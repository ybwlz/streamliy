import pandas as pd # ç”¨äºæ•°æ®å¤„ç†
import numpy as np # ç”¨äºæ•°å€¼è®¡ç®—
import plotly.graph_objects as go #ç”¨äºç»˜åˆ¶äº¤äº’å¼å›¾è¡¨# .graph_objectsæ˜¯Plotlyä¸­ç”¨äºåˆ›å»ºå›¾è¡¨çš„æ ¸å¿ƒæ¨¡å—,åŒ…å«å„ç§å›¾è¡¨ç±»å‹å’Œå¸ƒå±€é…ç½®ï¼Œæ¯”å¦‚æ•£ç‚¹å›¾ã€æŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ç­‰ï¼Œè¿˜æœ‰å¸ƒå±€å’Œæ ·å¼è®¾ç½®
from plotly.subplots import make_subplots # ç”¨äºåˆ›å»ºå­å›¾
import streamlit as st # ç”¨äºæ„å»ºWebåº”ç”¨
import warnings # ç”¨äºå¿½ç•¥è­¦å‘Šä¿¡æ¯
warnings.filterwarnings('ignore') # å¿½ç•¥è­¦å‘Šä¿¡æ¯ï¼Œfilterwarnings()å‡½æ•°ç”¨äºæ§åˆ¶è­¦å‘Šçš„æ˜¾ç¤ºè¡Œä¸ºï¼Œè¿™é‡Œè®¾ç½®ä¸ºå¿½ç•¥æ‰€æœ‰è­¦å‘Šä¿¡æ¯


#å‰¯æœ¬ï¼Œå¤åˆ¶ç‰ˆï¼Œè¯¦æƒ…æ³¨é‡Šç‰ˆ


# ========== åŸºå‡†æ•°æ® ==========
# æ ¹æ®jiaoyi.csvçš„æ—¥æœŸèŒƒå›´è·å–çš„é»„é‡‘æœŸè´§åŸºå‡†æ”¶ç›Šç‡æ•°æ®ï¼ˆä½¿ç”¨AU0ä¸»åŠ›è¿ç»­åˆçº¦ï¼‰
# æ•°æ®æ ¼å¼ï¼šä¸äº¤æ˜“æ—¥æœŸå¯¹é½çš„æ—¥æ”¶ç›Šç‡åºåˆ—ï¼ˆå°æ•°å½¢å¼ï¼‰
# åŸºå‡†æ•°æ®æ—¥æœŸèŒƒå›´: 2024-01-04 åˆ° 2025-04-28ï¼Œå…±71ä¸ªäº¤æ˜“æ—¥
# æ³¨æ„ï¼šç¬¬ä¸€ä¸ªå€¼ä¸º0ï¼Œå› ä¸ºç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥æ²¡æœ‰å‰ä¸€å¤©çš„ä»·æ ¼æ•°æ®
# åŸºå‡†æ•°æ®æ¥æºï¼šakshareè·å–çš„AU0é»„é‡‘ä¸»åŠ›è¿ç»­åˆçº¦ï¼Œæ•´ä¸ªæœŸé—´ï¼ˆ315ä¸ªè¿ç»­äº¤æ˜“æ—¥ï¼‰æ€»æ”¶ç›Šç‡61.95%
# å¯¹é½è¯´æ˜ï¼šä½¿ç”¨æ•´ä¸ªæœŸé—´çš„è¿ç»­åŸºå‡†æ•°æ®ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥ä½¿ç”¨ä»ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥åˆ°è¯¥äº¤æ˜“æ—¥ä¹‹é—´çš„ç´¯è®¡åŸºå‡†æ”¶ç›Šç‡
# å¯¹é½åçš„åŸºå‡†æ•°æ®æ€»æ”¶ç›Šç‡ï¼š62.56%ï¼ˆä¸è¿ç»­åŸºå‡†æ€»æ”¶ç›Šç‡61.95%éå¸¸æ¥è¿‘ï¼Œå·®å¼‚0.60%ï¼‰

#BENCHMARKï¼šè¡¨æ˜è¿™æ˜¯åŸºå‡†/å¯¹æ¯”æ ‡å‡†benchmark
#RETURNSï¼šè¡¨ç¤ºè¿™æ˜¯æ”¶ç›Šç‡æ•°æ®returns
#HARDCODEDï¼šè¡¨æ˜æ˜¯ç¡¬ç¼–ç /å†…åµŒåœ¨ä»£ç ä¸­çš„æ•°æ®ï¼ˆè€Œä¸æ˜¯ä»å¤–éƒ¨æ–‡ä»¶/APIå®æ—¶è·å–ï¼‰hardcoded
#å¤§å†™å­—æ¯å’Œä¸‹åˆ’çº¿å‘½åé£æ ¼ï¼Œç¬¦åˆå¸¸é‡å‘½åè§„èŒƒ

BENCHMARK_RETURNS_HARDCODED = np.array([ 
    0.00000000, 0.00079190, -0.00283192, 0.00062646, -0.00488334, 0.01673517, -0.00858050, -0.00124828, 0.00283298, -0.00029081,
    0.05290060, 0.00280223, 0.09260863, 0.02121681, -0.00261023, -0.03656811, 0.00998458, 0.00214436, -0.00569398, 0.01148964,
    -0.00025243, 0.00941423, -0.00982669, -0.00476362, -0.00638190, 0.00080286, 0.00291715, 0.00199971, -0.01048659, 0.01298130,
    0.00582827, 0.00906964, 0.00841745, -0.00010611, -0.00597807, 0.00882531, 0.00134044, 0.01490119, -0.00045123, -0.00888981,
    -0.00455485, 0.05490831, -0.01811751, 0.00363599, 0.02133062, 0.05363832, -0.00934462, -0.00898812, -0.02041470, -0.00925865,
    0.00815639, 0.00959712, -0.00528826, 0.01063275, -0.00196863, -0.00737268, 0.00824185, -0.00216478, 0.01868342, 0.08521933,
    0.01051522, -0.02394203, 0.00074241, 0.01249295, 0.03599062, 0.00472445, 0.01109390, 0.06441282, 0.02595364, 0.00372316,
    -0.00909553
])

BENCHMARK_AVAILABLE = True # é€šå¸¸ç”¨äºåç»­é¢çš„æ¡ä»¶åˆ¤æ–­

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config( #st.set_page_config()å‡½æ•°ç”¨äºè®¾ç½®Streamlitåº”ç”¨çš„é¡µé¢é…ç½®
    page_title="ç­–ç•¥é£é™©åˆ†æ", 
    page_icon="ğŸ“Š", 
    layout="wide" , #layoutå‚æ•°è®¾ç½®ä¸º"wide"ï¼Œè¡¨ç¤ºé¡µé¢å¸ƒå±€ä¸ºå®½å±æ¨¡å¼,è¿˜æœ‰"centered"æ¨¡å¼å¯é€‰ï¼Œä»£è¡¨ä¸­é—´å¯¹é½
)

# åŠ è½½äº¤æ˜“æ•°æ®ï¼ˆä½¿ç”¨GBKç¼–ç ï¼‰
@st.cache_data   #ç¼“å­˜æ•°æ®ä»¥æé«˜æ€§èƒ½
def load_trade_data(filename='jiaoyi.csv'): 
    """åŠ è½½äº¤æ˜“æ•°æ®"""
    import os
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•D :\code\flask\task3
    script_dir = os.path.dirname(os.path.abspath(__file__)) #os.path.abspath(__file__)è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„ï¼Œos.path.dirname()è·å–å…¶çˆ¶ç›®å½•
    
    # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
    possible_paths = [
        os.path.join(script_dir, filename),  # è„šæœ¬æ‰€åœ¨ç›®å½• D :\code\flask\task3\jiaoyi.csv
        filename,  # å½“å‰å·¥ä½œç›®å½• D :\code\flask\jiaoyi.csv
        os.path.join('.', filename),  # å½“å‰ç›®å½• ./jiaoyi.csv
        os.path.join('task3', filename),  # task3å­ç›®å½• task3/jiaoyi.csv
    ]
    
    for file_path in possible_paths:
        try:
            if os.path.exists(file_path):
                df = pd.read_csv(file_path, encoding='gbk')
                return df
        except Exception as e:
            continue
    
    # å¦‚æœæ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    st.error(f"æ— æ³•æ‰¾åˆ°æ–‡ä»¶: {filename}") #é»„è‰²è­¦å‘Šæç¤º
    st.info("**è°ƒè¯•ä¿¡æ¯ï¼š**") #è“è‰²ä¿¡æ¯æç¤º**ä»£è¡¨åŠ ç²—ï¼Œè¿˜æœ‰æ–œä½“ç­‰Markdownè¯­æ³•ï¼Œæ¯”å¦‚*æ–œä½“*ï¼Œæˆ–è€…`ä»£ç å—`ï¼Œè¿˜æœ‰åˆ—è¡¨ç­‰ï¼Œæ¯”å¦‚- åˆ—è¡¨é¡¹1ï¼Œæˆ–è€…1. åˆ—è¡¨é¡¹1
    st.info(f"- è„šæœ¬æ‰€åœ¨ç›®å½•: {script_dir}") #f-stringsç”¨äºæ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼Œ{script_dir}ä¼šè¢«æ›¿æ¢ä¸ºå˜é‡script_dirçš„å€¼
    st.info(f"- å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}") #os.getcwd()è·å–å½“å‰å·¥ä½œç›®å½•
    st.info(f"- å°è¯•çš„è·¯å¾„: {', '.join(possible_paths)}") #join()æ–¹æ³•ç”¨äºå°†åˆ—è¡¨å…ƒç´ è¿æ¥æˆå­—ç¬¦ä¸²ï¼Œé€šè¿‡', 'åˆ†éš”
    
    # åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    try:
        current_files = os.listdir('.') #os.listdir('.') åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
        #f for f in current_files if f.endswith('.csv') ç›¸å½“äº
        #for f in current_files:
        #    if f.endswith('.csv'):
        #        ç»“æœ.append(f)
        st.info(f"- å½“å‰ç›®å½•æ–‡ä»¶: {', '.join([f for f in current_files if f.endswith('.csv')][:5])}")#endswith()æ–¹æ³•ç”¨äºåˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦ä»¥æŒ‡å®šåç¼€ç»“å°¾,[:5]è¡¨ç¤ºåªæ˜¾ç¤ºå‰äº”ä¸ªæ–‡ä»¶
    except:
        pass
    
    try:
        script_files = os.listdir(script_dir)
        st.info(f"- è„šæœ¬ç›®å½•æ–‡ä»¶: {', '.join([f for f in script_files if f.endswith('.csv')][:5])}")
    except:
        pass
    
    return None

# æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
def preprocess_data(df):
    """é¢„å¤„ç†äº¤æ˜“æ•°æ®"""
    df = df.copy() #è¿™æ˜¯pandasçš„æ–¹æ³•ï¼Œç”¨äºåˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    
    # åˆå¹¶æ—¥æœŸå’Œæ—¶é—´
    try:
        #pd.to_datetime()å‡½æ•°ç”¨äºå°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´æ ¼å¼,astype(str)ç¡®ä¿æ•°æ®æ˜¯å­—ç¬¦ä¸²ç±»å‹,formatæŒ‡å®šæ—¥æœŸæ—¶é—´æ ¼å¼ï¼Œerrors='coerce'ä¼šå°†æ— æ³•è§£æçš„å€¼è½¬æ¢NaN,+å·è¿æ¥å­—ç¬¦ä¸²
        df['æ—¥æœŸæ—¶é—´'] = pd.to_datetime(df['æ—¥æœŸ'].astype(str) + ' ' + df['å§”æ‰˜æ—¶é—´'].astype(str), 
                                      format='%Y/%m/%d %H:%M:%S', errors='coerce')
    #exceptæ²¡æœ‰æŒ‡å®šformatæ—¶çš„å¤‡ç”¨æ–¹æ¡ˆï¼Œä¼šè‡ªåŠ¨æ¨æ–­æ ¼å¼
    except:
        df['æ—¥æœŸæ—¶é—´'] = pd.to_datetime(df['æ—¥æœŸ'].astype(str) + ' ' + df['å§”æ‰˜æ—¶é—´'].astype(str), errors='coerce')
    
    #.sort_values()ç”¨äºæŒ‰æŒ‡å®šåˆ—æ’åºï¼Œreset_index(drop=True)ç”¨äºé‡ç½®ç´¢å¼•ï¼Œdrop=Trueè¡¨ç¤ºä¸ä¿ç•™æ—§ç´¢å¼•
    df = df.sort_values('æ—¥æœŸæ—¶é—´').reset_index(drop=True)
    
    # è½¬æ¢æ•°æ®ç±»å‹
    # æˆäº¤æ•°é‡ï¼ˆå¤„ç†"æ‰‹"å•ä½ï¼‰
    #df.columnsç”¨äºè·å–DataFrameçš„åˆ—ååˆ—è¡¨
    if 'æˆäº¤æ•°é‡' in df.columns:
        # .dtypeå±æ€§ç”¨äºè·å–åˆ—çš„æ•°æ®ç±»å‹ï¼Œobjectè¡¨ç¤ºå­—ç¬¦ä¸²ç±»å‹,åœ¨pdé‡Œé¢
        if df['æˆäº¤æ•°é‡'].dtype == 'object':
            # .astype(str)ç¡®ä¿æ•°æ®æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œ.str.replace()ç”¨äºæ›¿æ¢å­—ç¬¦ä¸²ä¸­çš„æŒ‡å®šå†…å®¹ï¼Œ.str.strip()ç”¨äºå»é™¤å­—ç¬¦ä¸²ä¸¤ç«¯çš„ç©ºç™½å­—ç¬¦
            df['æˆäº¤æ•°é‡'] = df['æˆäº¤æ•°é‡'].astype(str).str.replace('æ‰‹', '').str.replace(',', '').str.strip()
            # .pd.to_numeric()ç”¨äºå°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼Œerrors='coerce'ä¼šå°†æ— æ³•è½¬æ¢çš„å€¼å˜ä¸ºNaN
            df['æˆäº¤æ•°é‡'] = pd.to_numeric(df['æˆäº¤æ•°é‡'], errors='coerce')
        else:
            df['æˆäº¤æ•°é‡'] = pd.to_numeric(df['æˆäº¤æ•°é‡'], errors='coerce')
    
    # æˆäº¤ä»·æ ¼ï¼ˆåˆ—åå¯èƒ½æ˜¯'æˆäº¤ä»·'ï¼‰
    price_col = 'æˆäº¤ä»·' if 'æˆäº¤ä»·' in df.columns else 'æˆäº¤ä»·æ ¼'
    if price_col in df.columns:
        if df[price_col].dtype == 'object':
            df[price_col] = df[price_col].astype(str).str.replace(',', '').str.strip()
        df[price_col] = pd.to_numeric(df[price_col], errors='coerce')
        # ç»Ÿä¸€åˆ—åä¸º'æˆäº¤ä»·æ ¼'
        if price_col != 'æˆäº¤ä»·æ ¼':
            df['æˆäº¤ä»·æ ¼'] = df[price_col]
    
    # æˆäº¤é‡‘é¢ï¼ˆåˆ—åå¯èƒ½æ˜¯'æˆäº¤é¢'ï¼‰
    amount_col = 'æˆäº¤é¢' if 'æˆäº¤é¢' in df.columns else 'æˆäº¤é‡‘é¢'
    if amount_col in df.columns:
        if df[amount_col].dtype == 'object':
            df[amount_col] = df[amount_col].astype(str).str.replace(',', '').str.strip()
        df[amount_col] = pd.to_numeric(df[amount_col], errors='coerce')
        # ç»Ÿä¸€åˆ—åä¸º'æˆäº¤é‡‘é¢'
        if amount_col != 'æˆäº¤é‡‘é¢':
            df['æˆäº¤é‡‘é¢'] = df[amount_col]
    
    # å¹³ä»“ç›ˆäºï¼ˆå¤„ç†"-"è¡¨ç¤º0çš„æƒ…å†µï¼‰
    if df['å¹³ä»“ç›ˆäº'].dtype == 'object':
        df['å¹³ä»“ç›ˆäº'] = df['å¹³ä»“ç›ˆäº'].astype(str).str.replace(',', '').str.strip()
        df['å¹³ä»“ç›ˆäº'] = df['å¹³ä»“ç›ˆäº'].replace(['-', ''], '0')
    df['å¹³ä»“ç›ˆäº'] = pd.to_numeric(df['å¹³ä»“ç›ˆäº'], errors='coerce').fillna(0)
    
    # æ‰‹ç»­è´¹
    if df['æ‰‹ç»­è´¹'].dtype == 'object':
        df['æ‰‹ç»­è´¹'] = df['æ‰‹ç»­è´¹'].astype(str).str.replace(',', '').str.strip()
        df['æ‰‹ç»­è´¹'] = df['æ‰‹ç»­è´¹'].replace(['-', ''], '0')
    df['æ‰‹ç»­è´¹'] = pd.to_numeric(df['æ‰‹ç»­è´¹'], errors='coerce').fillna(0)
    
    # è®¡ç®—æ¯ç¬”äº¤æ˜“çš„å‡€ç›ˆäºï¼ˆå¹³ä»“ç›ˆäº - æ‰‹ç»­è´¹ï¼‰
    df['å‡€ç›ˆäº'] = df['å¹³ä»“ç›ˆäº'] - df['æ‰‹ç»­è´¹']
    
    return df



# è®¡ç®—é£é™©æŒ‡æ ‡
#è¿™äº›å‚æ•°æ˜¯å‡½æ•°calculate_risk_metricsçš„è¾“å…¥å‚æ•°ï¼Œåˆ†åˆ«æ—¥æœŸæ”¶ç›Šç‡åºåˆ—ã€æ€»æ”¶ç›Šç‡ã€åˆå§‹èµ„é‡‘ã€æ—¥ç›ˆäºæ•°æ®å’ŒåŸºå‡†æ”¶ç›Šç‡æ•°æ®
def calculate_risk_metrics(daily_returns, total_returns, initial_capital, daily_pnl, benchmark_returns=None):
    """è®¡ç®—å„ç§é£é™©æŒ‡æ ‡"""
    metrics = {}
    
    # ç¡®ä¿daily_returnsæ˜¯æ•°ç»„
    if isinstance(daily_returns, pd.Series): #isinstance()å‡½æ•°ç”¨äºæ£€æŸ¥å˜é‡ç±»å‹,æ„æ€æ˜¯å¦‚æœdaily_returnsæ˜¯pandasçš„Seriesç±»å‹
        daily_returns = daily_returns.values #.valueså±æ€§ç”¨äºè·å–Seriesçš„åº•å±‚NumPyæ•°ç»„,ä¹‹æ‰€ä»¥æ˜¯å› ä¸ºåç»­è®¡ç®—éœ€è¦ä½¿ç”¨NumPyæ•°ç»„è¿›è¡Œæ•°å€¼è®¡ç®—,ç›¸å½“äºå°±æ˜¯å­—å…¸æŠŠkeyå–å‡ºæ¥ï¼Œå°±æ˜¯numpyæ•°ç»„
    
    # è¿‡æ»¤NaNå€¼
    daily_returns = daily_returns[~np.isnan(daily_returns)]#~è¡¨ç¤ºå–åï¼Œnp.isnan()ç”¨äºåˆ¤æ–­NaNå€¼ï¼Œ~np.isnan()è¡¨ç¤ºéNaNå€¼
    

    #é˜²å¾¡æ€§ç¼–ç¨‹ï¼šå¦‚æœdaily_returnsé•¿åº¦ä¸º0ï¼Œç›´æ¥è¿”å›ç©ºå­—å…¸ï¼Œé¿å…åç»­è®¡ç®—å‡ºé”™
    if len(daily_returns) == 0:
        return {}
    
    # Total Returns ç­–ç•¥æ”¶ç›Šï¼ˆç™¾åˆ†æ¯”ï¼‰
    metrics['Total Returns'] = total_returns
    
    # Total Annualized Returns ç­–ç•¥å¹´åŒ–æ”¶ç›Š
    trading_days = len(daily_returns)
    if trading_days > 0:
        # è®¡ç®—å®é™…äº¤æ˜“å¤©æ•°
        date_range = (daily_pnl['æ—¥æœŸ'].max() - daily_pnl['æ—¥æœŸ'].min()).days  #daily_pnlæ˜¯ä¸€ä¸ªDataFrameï¼ŒåŒ…å«æ¯æ—¥ç›ˆäºæ•°æ®ï¼Œ'æ—¥æœŸ'åˆ—æ˜¯æ—¥æœŸç±»å‹ï¼Œ.max()å’Œ.min()åˆ†åˆ«è·å–æœ€å¤§å’Œæœ€å°æ—¥æœŸï¼Œ
                                                                               #.dayså±æ€§è·å–ä¸¤ä¸ªæ—¥æœŸä¹‹é—´çš„å¤©æ•°å·®
        years = date_range / 365.25 if date_range > 0 else trading_days / 252 #è€ƒè™‘é—°å¹´ï¼Œä½¿ç”¨365.25å¤©/å¹´ï¼Œå¦‚æœdate_rangeä¸º0ï¼Œåˆ™é€€åŒ–ä¸ºtrading_days/252ï¼Œä¹‹æ‰€ä»¥æ˜¯252æ˜¯å› ä¸ºé€šå¸¸è®¤ä¸ºæ¯å¹´æœ‰252ä¸ªäº¤æ˜“æ—¥
        #è€Œä¹‹æ‰€ä»¥åœ¨date_rangeä¸º0æ—¶ä½¿ç”¨trading_days/252ï¼Œæ˜¯ä¸ºäº†é¿å…é™¤ä»¥é›¶çš„æƒ…å†µï¼ŒåŒæ—¶ä¹Ÿèƒ½åœ¨æç«¯æƒ…å†µä¸‹æä¾›ä¸€ä¸ªåˆç†çš„å¹´åŒ–æ”¶ç›Šä¼°è®¡
        if years > 0:
            metrics['Total Annualized Returns'] = ((1 + total_returns / 100) ** (1 / years) - 1) * 100
        else:
            metrics['Total Annualized Returns'] = 0
    else:
        metrics['Total Annualized Returns'] = 0
    
    # Algorithm Volatility ç­–ç•¥æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–ï¼‰å°±æ˜¯ç­–ç•¥æ”¶ç›Šçš„å¹´åŒ–æ ‡å‡†å·®
    if len(daily_returns) > 1:
        metrics['Algorithm Volatility'] = np.std(daily_returns) * np.sqrt(252) * 100 #.sqrt(252)ç”¨äºå°†æ—¥æ ‡å‡†å·®è½¬æ¢ä¸ºå¹´åŒ–æ ‡å‡†å·®ï¼Œä¹˜ä»¥100è½¬æ¢ä¸ºç™¾åˆ†æ¯”å½¢å¼
    else:
        metrics['Algorithm Volatility'] = 0
    
    # Benchmark Volatility åŸºå‡†æ³¢åŠ¨ç‡ï¼ˆå°±æ˜¯åŸºå‡†æ”¶ç›Šçš„å¹´åŒ–æ ‡å‡†å·®ï¼‰
    if benchmark_returns is not None and len(benchmark_returns) > 1:
        metrics['Benchmark Volatility'] = np.std(benchmark_returns) * np.sqrt(252) * 100#np.sqrt(252)ç›¸å½“äº
    else:
        metrics['Benchmark Volatility'] = 0
    
    # Sharpe å¤æ™®æ¯”ç‡ï¼ˆå‡è®¾æ— é£é™©åˆ©ç‡ä¸º0ï¼‰
    if metrics['Algorithm Volatility'] > 0:
        metrics['Sharpe'] = metrics['Total Annualized Returns'] / metrics['Algorithm Volatility']
    else:
        metrics['Sharpe'] = 0
    
    # Sortino ç´¢æè¯ºæ¯”ç‡ï¼ˆåªè€ƒè™‘ä¸‹è¡Œæ³¢åŠ¨ï¼‰å°±æ˜¯åªè®¡ç®—è´Ÿæ”¶ç›Šçš„æ ‡å‡†å·®
    downside_returns = daily_returns[daily_returns < 0]
    if len(downside_returns) > 1:
        downside_std = np.std(downside_returns) * np.sqrt(252) * 100
        metrics['Downside Risk'] = downside_std#ç­–ç•¥ä¸‹è¡Œæ³¢åŠ¨ç‡
        if downside_std > 0:#é¿å…é™¤é›¶é”™è¯¯
            metrics['Sortino'] = metrics['Total Annualized Returns'] / downside_std#ç´¢æè¯ºæ¯”ç‡ï¼ˆç­–ç•¥å¹´åŒ–æ”¶ç›Šç‡ - æ— é£é™©åˆ©ç‡ï¼‰/ç­–ç•¥ä¸‹è¡Œæ³¢åŠ¨ç‡
        else:
            metrics['Sortino'] = 0
    else:
        metrics['Downside Risk'] = 0#ç­–ç•¥ä¸‹è¡Œæ³¢åŠ¨ç‡ä¸º0
        metrics['Sortino'] = 0#ç´¢æè¯ºæ¯”ç‡ä¸º0
    
    # Max Drawdown æœ€å¤§å›æ’¤
    # ä½¿ç”¨å¤åˆ©è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡ï¼š(1 + r1) * (1 + r2) * ... - 1
    cumulative_returns = np.cumprod(1 + daily_returns) - 1 #np.cumprod()ç”¨äºè®¡ç®—ç´¯ç§¯ä¹˜ç§¯
    running_max = np.maximum.accumulate(cumulative_returns) #np.maximum.accumulate()ç”¨äºè®¡ç®—è¿è¡Œä¸­çš„æœ€å¤§å€¼
    drawdown = cumulative_returns - running_max
    # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
    metrics['Max Drawdown'] = np.min(drawdown) * 100 if len(drawdown) > 0 else 0
    
    # Alpha å’Œ Betaï¼ˆä½¿ç”¨æ•´ä¸ªæœŸé—´çš„315ä¸ªäº¤æ˜“æ—¥çš„è¿ç»­åŸºå‡†æ•°æ®ï¼‰
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 1 and len(benchmark_returns_clean) > 1:
            # è®¡ç®—åæ–¹å·®å’Œæ–¹å·®
            covariance = np.cov(daily_returns_clean, benchmark_returns_clean)[0, 1]
            benchmark_variance = np.var(benchmark_returns_clean, ddof=0)
            
            if benchmark_variance > 1e-10:  # é¿å…é™¤é›¶
                metrics['Beta'] = covariance / benchmark_variance
                
                # Alpha = (ç­–ç•¥å¹³å‡æ—¥æ”¶ç›Šç‡ - Beta * åŸºå‡†å¹³å‡æ—¥æ”¶ç›Šç‡) * 252 * 100
                # daily_returns å’Œ benchmark_returns éƒ½æ˜¯å°æ•°å½¢å¼ï¼ˆ0.01è¡¨ç¤º1%ï¼‰
                strategy_mean_daily = np.mean(daily_returns_clean)
                benchmark_mean_daily = np.mean(benchmark_returns_clean)
                alpha_daily = strategy_mean_daily - metrics['Beta'] * benchmark_mean_daily
                # å¹´åŒ–Alphaï¼ˆè½¬æ¢ä¸ºç™¾åˆ†æ¯”ï¼‰
                metrics['Alpha'] = alpha_daily * 252 * 100
                
                # éªŒè¯Alphaå€¼çš„åˆç†æ€§ï¼ˆé€šå¸¸åº”è¯¥åœ¨-100%åˆ°+100%ä¹‹é—´ï¼‰
                if abs(metrics['Alpha']) > 200:
                    print(f"è­¦å‘Š: Alphaå€¼å¼‚å¸¸é«˜ ({metrics['Alpha']:.2f}%)ï¼Œè¯·æ£€æŸ¥åŸºå‡†æ•°æ®æ˜¯å¦æ­£ç¡®")
                    print(f"  ç­–ç•¥å¹³å‡æ—¥æ”¶ç›Šç‡: {strategy_mean_daily*100:.4f}%")
                    print(f"  åŸºå‡†å¹³å‡æ—¥æ”¶ç›Šç‡: {benchmark_mean_daily*100:.4f}%")
                    print(f"  Beta: {metrics['Beta']:.4f}")
            else:
                metrics['Beta'] = 0
                metrics['Alpha'] = 0
            
            # Information Ratio ä¿¡æ¯æ¯”ç‡
            excess_returns = daily_returns_clean - benchmark_returns_clean
            if len(excess_returns) > 1:
                tracking_error = np.std(excess_returns, ddof=0) * np.sqrt(252) * 100
                excess_return_mean = np.mean(excess_returns)
                excess_return_annual = excess_return_mean * 252 * 100
                
                if tracking_error > 1e-10:
                    metrics['Information Ratio'] = excess_return_annual / tracking_error
                else:
                    metrics['Information Ratio'] = 0
            else:
                metrics['Information Ratio'] = 0
        else:
            metrics['Beta'] = 0
            metrics['Alpha'] = 0
            metrics['Information Ratio'] = 0
    else:
        metrics['Alpha'] = 0
        metrics['Beta'] = 0
        metrics['Information Ratio'] = 0
    
    # èƒœç‡ï¼ˆæŒ‰äº¤æ˜“ç¬”æ•°ï¼‰
    winning_trades = (daily_returns > 0).sum()
    total_trades = len(daily_returns)
    metrics['èƒœç‡'] = (winning_trades / total_trades * 100) if total_trades > 0 else 0
    
    # æ—¥èƒœç‡ï¼ˆæŒ‰æ—¥ç»Ÿè®¡ï¼‰ï¼šå½“æ—¥ç­–ç•¥æ”¶ç›Šè·‘èµ¢å½“æ—¥åŸºå‡†æ”¶ç›Šçš„å¤©æ•° / æ€»äº¤æ˜“æ—¥æ•°
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) |  #isnan()ç”¨äºåˆ¤æ–­NaNå€¼
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned)) #isinf()ç”¨äºåˆ¤æ–­æ— ç©·å€¼ ä¹‹æ‰€ä»¥~æ˜¯å› ä¸ºå–éè¿™äº›çš„å€¼
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            # ç»Ÿè®¡ç­–ç•¥æ”¶ç›Šè·‘èµ¢åŸºå‡†æ”¶ç›Šçš„å¤©æ•°
            winning_days = (daily_returns_clean > benchmark_returns_clean).sum()
            total_days = len(daily_returns_clean)
            metrics['æ—¥èƒœç‡'] = (winning_days / total_days * 100) if total_days > 0 else 0
        else:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„åŸºå‡†æ•°æ®ï¼Œå›é€€åˆ°åŸæ¥çš„è®¡ç®—æ–¹æ³•
            winning_days = (daily_pnl['æ—¥ç›ˆäº'] > 0).sum()
            total_days = len(daily_pnl)
            metrics['æ—¥èƒœç‡'] = (winning_days / total_days * 100) if total_days > 0 else 0
    else:
        # å¦‚æœæ²¡æœ‰åŸºå‡†æ•°æ®ï¼Œä½¿ç”¨åŸæ¥çš„è®¡ç®—æ–¹æ³•ï¼ˆæ—¥ç›ˆäº>0çš„å¤©æ•°ï¼‰
        winning_days = (daily_pnl['æ—¥ç›ˆäº'] > 0).sum()
        total_days = len(daily_pnl)
        metrics['æ—¥èƒœç‡'] = (winning_days / total_days * 100) if total_days > 0 else 0
    
    # ç›ˆäºæ¯”
    if winning_trades > 0 and (total_trades - winning_trades) > 0:
        avg_win = daily_returns[daily_returns > 0].mean()
        avg_loss = abs(daily_returns[daily_returns < 0].mean())
        metrics['ç›ˆäºæ¯”'] = avg_win / avg_loss if avg_loss > 0 else 0
    else:
        metrics['ç›ˆäºæ¯”'] = 0
    
    # AEI æ—¥å‡è¶…é¢æ”¶ç›Šï¼ˆå¦‚æœæœ‰åŸºå‡†ï¼‰
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            excess_returns = daily_returns_clean - benchmark_returns_clean
            metrics['AEI'] = np.mean(excess_returns) * 100
        else:
            metrics['AEI'] = 0
    else:
        metrics['AEI'] = 0
    
    # è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            excess_returns = daily_returns_clean - benchmark_returns_clean
            # ä½¿ç”¨å¤åˆ©è®¡ç®—ç´¯è®¡è¶…é¢æ”¶ç›Šç‡
            excess_cumulative = np.cumprod(1 + excess_returns) - 1 #np.cumprod()ç”¨äºè®¡ç®—ç´¯ç§¯ä¹˜ç§¯
            excess_running_max = np.maximum.accumulate(excess_cumulative)
            excess_drawdown = excess_cumulative - excess_running_max
            # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            metrics['è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤'] = np.min(excess_drawdown) * 100 if len(excess_drawdown) > 0 else 0
        else:
            metrics['è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤'] = 0
    else:
        metrics['è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤'] = 0
    
    # è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 1:
            excess_returns = daily_returns_clean - benchmark_returns_clean
            excess_vol = np.std(excess_returns, ddof=0) * np.sqrt(252) * 100
            excess_mean = np.mean(excess_returns) * 252 * 100
            metrics['è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡'] = excess_mean / excess_vol if excess_vol > 1e-10 else 0
        else:
            metrics['è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡'] = 0
    else:
        metrics['è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡'] = 0
    
    # è¶…é¢æ”¶ç›Šï¼ˆé™¤æ³•ç‰ˆï¼‰- (ç­–ç•¥æ€»æ”¶ç›Šç‡ / åŸºå‡†æ€»æ”¶ç›Šç‡ - 1) * 100
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            # ä½¿ç”¨å¤åˆ©è®¡ç®—æ€»æ”¶ç›Šç‡ï¼š(1 + r1) * (1 + r2) * ... - 1
            strategy_total = np.prod(1 + daily_returns_clean) - 1 #np.prod()ç”¨äºè®¡ç®—æ•°ç»„å…ƒç´ çš„ä¹˜ç§¯ï¼Œå’Œcumprod()ä¸åŒï¼Œcumprod()æ˜¯ç´¯ç§¯ä¹˜ç§¯
            benchmark_total = np.prod(1 + benchmark_returns_clean) - 1
            
            if abs(benchmark_total) > 1e-10:
                # è¶…é¢æ”¶ç›Š = (ç­–ç•¥æ€»æ”¶ç›Š / åŸºå‡†æ€»æ”¶ç›Š - 1) * 100
                metrics['è¶…é¢æ”¶ç›Š'] = (strategy_total / benchmark_total - 1) * 100
            else:
                metrics['è¶…é¢æ”¶ç›Š'] = 0
        else:
            metrics['è¶…é¢æ”¶ç›Š'] = 0
    else:
        metrics['è¶…é¢æ”¶ç›Š'] = 0
    
    # å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š
    # è®¡ç®—æ–¹æ³•ï¼šlog(1 + ç­–ç•¥æ€»æ”¶ç›Šç‡) - log(1 + åŸºå‡†æ€»æ”¶ç›Šç‡)
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            # ä½¿ç”¨å¤åˆ©è®¡ç®—æ€»æ”¶ç›Šç‡ï¼š(1 + r1) * (1 + r2) * ... - 1
            strategy_total = np.prod(1 + daily_returns_clean) - 1
            benchmark_total = np.prod(1 + benchmark_returns_clean) - 1
            # ä½¿ç”¨log1pé¿å…log(0)çš„é—®é¢˜
            log_excess = np.log1p(strategy_total) - np.log1p(benchmark_total)
            metrics['å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š'] = log_excess * 100
        else:
            metrics['å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š'] = 0
    else:
        metrics['å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š'] = 0
    
    return metrics

# ç»˜åˆ¶äº¤æ˜“ä¿¡å·å›¾
def plot_trading_signals(df):
    """
    ç»˜åˆ¶äº¤æ˜“ä¿¡å·å›¾ï¼Œæ˜¾ç¤ºä»·æ ¼èµ°åŠ¿å’Œä¹°å–ä¿¡å·ç‚¹
    """
    # åˆ›å»ºå­å›¾ï¼šä»·æ ¼èµ°åŠ¿ + ç´¯è®¡æ”¶ç›Š
    fig = make_subplots(#make_subplotsæ˜¯Plotlyä¸­ç”¨äºåˆ›å»ºåŒ…å«å¤šä¸ªå­å›¾çš„å›¾è¡¨å¸ƒå±€çš„å‡½æ•°ï¼ŒåŒ…å«çš„å‚æ•°æœ‰rowsï¼ˆè¡Œæ•°ï¼‰ã€colsï¼ˆåˆ—æ•°ï¼‰ã€subplot_titlesï¼ˆå­å›¾æ ‡é¢˜åˆ—è¡¨ï¼‰ã€
                         # vertical_spacingï¼ˆå­å›¾ä¹‹é—´çš„å‚ç›´é—´è·ï¼‰å’Œ row_heightsï¼ˆæ¯è¡Œçš„é«˜åº¦æ¯”ä¾‹åˆ—è¡¨ï¼‰è¿˜æœ‰å…¶ä»–å‚æ•°æ¯”å¦‚horizontal_spacingï¼ˆå­å›¾ä¹‹é—´çš„æ°´å¹³é—´è·ï¼‰ã€shared_xaxesï¼ˆæ˜¯å¦å…±äº«Xè½´ï¼‰
                         # è¿˜æœ‰shared_yaxesï¼ˆæ˜¯å¦å…±äº«Yè½´ï¼‰è¿˜æœ‰specsï¼ˆå­å›¾è§„æ ¼åˆ—è¡¨ï¼‰è¿˜æœ‰column_widthsï¼ˆæ¯åˆ—çš„å®½åº¦æ¯”ä¾‹åˆ—è¡¨ï¼‰è¿˜æœ‰subplot_titles_fontï¼ˆå­å›¾æ ‡é¢˜å­—ä½“å±æ€§ï¼‰
                         # title_textï¼ˆå›¾è¡¨æ ‡é¢˜æ–‡æœ¬ï¼‰ï¼Œtitle_xï¼ˆå›¾è¡¨æ ‡é¢˜ä½ç½®ï¼‰ï¼Œå…·ä½“å¯å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼šhttps://plotly.com/python/subplots/
        rows=2, cols=1,
        subplot_titles=('äº¤æ˜“ä¿¡å·å›¾ï¼ˆä»·æ ¼èµ°åŠ¿ï¼‰', 'ç´¯è®¡æ”¶ç›Šæ›²çº¿'),
        vertical_spacing=0.1, #å­å›¾ä¹‹é—´çš„å‚ç›´é—´è·
        row_heights=[0.6, 0.4] #æ¯è¡Œå­å›¾çš„é«˜åº¦æ¯”ä¾‹
    )
    
    # æŒ‰æ—¥æœŸæ—¶é—´æ’åº
    df_sorted = df.sort_values('æ—¥æœŸæ—¶é—´').reset_index(drop=True)
    
    # 1. ä»·æ ¼èµ°åŠ¿å›¾ï¼ˆä¸»å›¾ï¼‰
    fig.add_trace( #add_trace()ç”¨äºå‘å›¾è¡¨æ·»åŠ æ•°æ®è½¨è¿¹
        go.Scatter( #go.Scatter()ç”¨äºåˆ›å»ºæ•£ç‚¹å›¾æˆ–æŠ˜çº¿å›¾,è¿˜æœ‰go.Bar()ç”¨äºåˆ›å»ºæŸ±çŠ¶å›¾ï¼Œæˆ–è€…go.Pie()ç”¨äºåˆ›å»ºé¥¼å›¾ç­‰ï¼Œkçº¿å›¾æ˜¯go.Candlestick()ï¼Œgo.Heatmap()ç”¨äºçƒ­åŠ›å›¾ç­‰ï¼Œgo.Histogram()ç”¨äºç›´æ–¹å›¾ç­‰
            #goä»£è¡¨Plotly Graph Objectsï¼Œæ˜¯Plotlyåº“ä¸­ç”¨äºåˆ›å»ºå›¾è¡¨çš„æ ¸å¿ƒæ¨¡å—
            x=df_sorted['æ—¥æœŸæ—¶é—´'],
            y=df_sorted['æˆäº¤ä»·æ ¼'],
            mode='lines',
            name='æˆäº¤ä»·æ ¼',
            line=dict(color='#1f77b4', width=1.5),
            hovertemplate='æ—¶é—´: %{x}<br>ä»·æ ¼: %{y:.2f}<extra></extra>'
        ),
        row=1, col=1
    )
    
    # æ ‡è®°ä¹°å…¥ä¿¡å·ï¼ˆå¼€å¤šï¼‰
    buy_signals = df_sorted[df_sorted['äº¤æ˜“ç±»å‹'].str.contains('å¼€å¤š', na=False)]
    if len(buy_signals) > 0:
        fig.add_trace(
            go.Scatter(
                x=buy_signals['æ—¥æœŸæ—¶é—´'],
                y=buy_signals['æˆäº¤ä»·æ ¼'],
                mode='markers',
                name='ä¹°å…¥ä¿¡å·ï¼ˆå¼€å¤šï¼‰',
                marker=dict(
                    symbol='triangle-up', #å‘ä¸Šä¸‰è§’å½¢
                    size=12,
                    color='green',
                    line=dict(width=2, color='darkgreen')
                ),
                hovertemplate='ä¹°å…¥æ—¶é—´: %{x}<br>ä»·æ ¼: %{y:.2f}<br>æ•°é‡: %{customdata}æ‰‹<extra></extra>',
                customdata=buy_signals['æˆäº¤æ•°é‡']
            ),
            row=1, col=1
        )
    
    # æ ‡è®°å–å‡ºä¿¡å·ï¼ˆå¹³å¤šï¼‰
    sell_signals = df_sorted[df_sorted['äº¤æ˜“ç±»å‹'].str.contains('å¹³å¤š', na=False)]
    if len(sell_signals) > 0:
        fig.add_trace(
            go.Scatter(
                x=sell_signals['æ—¥æœŸæ—¶é—´'],
                y=sell_signals['æˆäº¤ä»·æ ¼'],
                mode='markers',
                name='å–å‡ºä¿¡å·ï¼ˆå¹³å¤šï¼‰',
                marker=dict(
                    symbol='triangle-down', #å‘ä¸‹ä¸‰è§’å½¢
                    size=12,
                    color='red',
                    line=dict(width=2, color='darkred') #lineç”¨äºè®¾ç½®æ ‡è®°è¾¹æ¡†å±æ€§
                ),
                hovertemplate='å–å‡ºæ—¶é—´: %{x}<br>ä»·æ ¼: %{y:.2f}<br>ç›ˆäº: %{customdata:.0f}<extra></extra>',
                customdata=sell_signals['å¹³ä»“ç›ˆäº']
            ),
            row=1, col=1
        )
    
    # 2. ç´¯è®¡æ”¶ç›Šæ›²çº¿ï¼ˆå‰¯å›¾ï¼‰
    df_sorted['ç´¯è®¡æ”¶ç›Š'] = df_sorted['å‡€ç›ˆäº'].cumsum()
    colors_profit = ['green' if x >= 0 else 'red' for x in df_sorted['å‡€ç›ˆäº']]
    
    fig.add_trace(
        go.Bar(
            x=df_sorted['æ—¥æœŸæ—¶é—´'],
            y=df_sorted['å‡€ç›ˆäº'],
            name='å•ç¬”ç›ˆäº',
            marker_color=colors_profit,
            hovertemplate='æ—¶é—´: %{x}<br>ç›ˆäº: %{y:,.0f}<extra></extra>'
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=df_sorted['æ—¥æœŸæ—¶é—´'],
            y=df_sorted['ç´¯è®¡æ”¶ç›Š'],
            mode='lines',
            name='ç´¯è®¡æ”¶ç›Š',
            line=dict(color='blue', width=2),
            hovertemplate='æ—¶é—´: %{x}<br>ç´¯è®¡æ”¶ç›Š: %{y:,.0f}<extra></extra>'
        ),
        row=2, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    fig.add_hline(y=0, line_dash="dash", line_color="gray", row=2, col=1)
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        height=800,
        title_text="äº¤æ˜“ä¿¡å·å›¾",
        title_x=0.5,
        showlegend=True,
        hovermode='x unified',
        template='plotly_white'
    )
    
    # æ›´æ–°Yè½´æ ‡ç­¾u
    fig.update_yaxes(title_text="ä»·æ ¼", row=1, col=1) #update_yaxes()ç”¨äºæ›´æ–°Yè½´å±æ€§,ä¸è¿™æ ·å°±ä¼šæ˜¾ç¤ºé»˜è®¤çš„yaxis title
    fig.update_yaxes(title_text="ç›ˆäº", row=2, col=1) #title_textç”¨äºè®¾ç½®Yè½´æ ‡é¢˜
    
    # æ›´æ–°Xè½´æ—¥æœŸæ ¼å¼ï¼ˆä¸æ˜¾ç¤ºæ ‡ç­¾ï¼Œåªè®¾ç½®æ—¥æœŸæ ¼å¼ï¼‰
    fig.update_xaxes(tickformat="%Y-%m-%d", row=1, col=1) #tickformatç”¨äºè®¾ç½®æ—¥æœŸæ ¼å¼
    fig.update_xaxes(tickformat="%Y-%m-%d", row=2, col=1)
    
    return fig 

# ç»˜åˆ¶é£é™©æŒ‡æ ‡å›¾è¡¨
def plot_risk_charts(df, daily_pnl, metrics, use_log_scale=False):
    """
    ä½¿ç”¨Plotlyç»˜åˆ¶é£é™©æŒ‡æ ‡å›¾è¡¨
    
    å‚æ•°:
    - use_log_scale: æ˜¯å¦ä½¿ç”¨å¯¹æ•°è½´ï¼ˆå¯¹æ•°è½´è¯´æ˜ï¼šåœ¨å¯¹æ•°è½´ä¸Šï¼Œç›¸åŒçš„ç™¾åˆ†æ¯”å˜åŒ–æ˜¾ç¤ºä¸ºç›¸åŒçš„è·ç¦»ï¼Œ
                      ä¾¿äºæ¯”è¾ƒä¸åŒè§„æ¨¡çš„æŠ•èµ„è¡¨ç°ã€‚å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š = log(1+ç­–ç•¥æ”¶ç›Š) - log(1+åŸºå‡†æ”¶ç›Š)ï¼‰
    """
    
    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=4, cols=1,
        subplot_titles=('ç´¯è®¡æ”¶ç›Šæ›²çº¿', 'æ—¥ç›ˆäºåˆ†å¸ƒ', 'å›æ’¤æ›²çº¿', 'ç´¯è®¡æ”¶ç›Šç‡æ›²çº¿'),
        vertical_spacing=0.06,
        row_heights=[0.35, 0.2, 0.2, 0.25]
    )
    
    # 1. ç´¯è®¡æ”¶ç›Šæ›²çº¿ï¼ˆä¸»å›¾ï¼‰
    y_data = daily_pnl['ç´¯è®¡æ”¶ç›Š']
    if use_log_scale and (y_data > 0).all():
        y_data = np.log1p(y_data - y_data.min() + 1)
        yaxis_title = "ç´¯è®¡æ”¶ç›Š (å¯¹æ•°è½´)"
    else:
        yaxis_title = "ç´¯è®¡æ”¶ç›Š"
    
    fig.add_trace(
        go.Scatter(
            x=daily_pnl['æ—¥æœŸ'],
            y=y_data,
            mode='lines',
            name='ç´¯è®¡æ”¶ç›Š',
            line=dict(color='#1f77b4', width=2),
            hovertemplate='æ—¥æœŸ: %{x}<br>ç´¯è®¡æ”¶ç›Š: %{y:,.0f}<extra></extra>'
        ),
        row=1, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    if not use_log_scale:
        fig.add_hline(y=0, line_dash="dash", line_color="gray", row=1, col=1)
    
    # 2. æ—¥ç›ˆäºåˆ†å¸ƒ
    colors = ['green' if x > 0 else 'red' for x in daily_pnl['æ—¥ç›ˆäº']]
    fig.add_trace(
        go.Bar(
            x=daily_pnl['æ—¥æœŸ'],
            y=daily_pnl['æ—¥ç›ˆäº'],
            name='æ—¥ç›ˆäº',
            marker_color=colors,
            hovertemplate='æ—¥æœŸ: %{x}<br>æ—¥ç›ˆäº: %{y:,.0f}<extra></extra>'
        ),
        row=2, col=1
    )
    
    # 3. å›æ’¤æ›²çº¿
    cumulative = daily_pnl['ç´¯è®¡æ”¶ç›Š'].values
    running_max = np.maximum.accumulate(cumulative)
    drawdown = cumulative - running_max
    
    fig.add_trace(
        go.Scatter( #Scatterç”¨äºç»˜åˆ¶æŠ˜çº¿å›¾æˆ–æ•£ç‚¹å›¾
            x=daily_pnl['æ—¥æœŸ'],
            y=drawdown,
            mode='lines',
            name='å›æ’¤',
            fill='tozeroy',
            fillcolor='rgba(255,0,0,0.3)',
            line=dict(color='red', width=1),
            hovertemplate='æ—¥æœŸ: %{x}<br>å›æ’¤: %{y:,.0f}<extra></extra>'
        ),
        row=3, col=1
    )
    
    # 4. ç´¯è®¡æ”¶ç›Šç‡æ›²çº¿
    fig.add_trace(
        go.Scatter(
            x=daily_pnl['æ—¥æœŸ'],
            y=daily_pnl['ç´¯è®¡æ”¶ç›Šç‡'],
            mode='lines',
            name='ç´¯è®¡æ”¶ç›Šç‡',
            line=dict(color='green', width=2),
            hovertemplate='æ—¥æœŸ: %{x}<br>ç´¯è®¡æ”¶ç›Šç‡: %{y:.2f}%<extra></extra>'
        ),
        row=4, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    fig.add_hline(y=0, line_dash="dash", line_color="gray", row=4, col=1)
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        height=1200,
        title_text="ç­–ç•¥é£é™©åˆ†æå›¾è¡¨",
        title_x=0.5,
        showlegend=True,
        hovermode='x unified',
        template='plotly_white'
    )
    
    # æ›´æ–°Yè½´æ ‡ç­¾
    fig.update_yaxes(title_text=yaxis_title, row=1, col=1)
    fig.update_yaxes(title_text="æ—¥ç›ˆäº", row=2, col=1)
    fig.update_yaxes(title_text="å›æ’¤", row=3, col=1)
    fig.update_yaxes(title_text="ç´¯è®¡æ”¶ç›Šç‡ (%)", row=4, col=1)
    
    # æ›´æ–°Xè½´æ—¥æœŸæ ¼å¼ï¼ˆä¸æ˜¾ç¤ºæ ‡ç­¾ï¼Œåªè®¾ç½®æ—¥æœŸæ ¼å¼ï¼‰
    fig.update_xaxes(tickformat="%Y-%m-%d", row=1, col=1)
    fig.update_xaxes(tickformat="%Y-%m-%d", row=2, col=1)
    fig.update_xaxes(tickformat="%Y-%m-%d", row=3, col=1)
    fig.update_xaxes(tickformat="%Y-%m-%d", row=4, col=1)
    
    # å¦‚æœä½¿ç”¨å¯¹æ•°è½´ï¼Œè®¾ç½®yè½´ç±»å‹
    if use_log_scale:
        fig.update_yaxes(type="log", row=1, col=1)
    
    return fig

# Streamlitä¸»ç•Œé¢
def main():
    st.title("ğŸ“Š ç­–ç•¥é£é™©åˆ†æç³»ç»Ÿ")
    
    # åŠ è½½æ•°æ®
    df = load_trade_data('jiaoyi.csv')
    
    if df is None:
        st.error("æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ jiaoyi.csv æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        return
    
    # æ•°æ®é¢„å¤„ç†
    with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
        df = preprocess_data(df)
        
        # è®¡ç®—ç´¯è®¡æ”¶ç›Š
        df['ç´¯è®¡æ”¶ç›Š'] = df['å‡€ç›ˆäº'].cumsum() #.cumsun()æ˜¯pandasçš„ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºè®¡ç®—ç´¯è®¡å’Œ
        
        # è®¡ç®—åˆå§‹èµ„é‡‘ï¼ˆä½¿ç”¨ç¬¬ä¸€ç¬”äº¤æ˜“çš„æˆäº¤é‡‘é¢ä½œä¸ºå‚è€ƒï¼‰
        initial_capital = abs(df['æˆäº¤é‡‘é¢'].iloc[0]) if len(df) > 0 and df['æˆäº¤é‡‘é¢'].iloc[0] != 0 else 1000000
        df['ç´¯è®¡æ”¶ç›Šç‡'] = (df['ç´¯è®¡æ”¶ç›Š'] / initial_capital) * 100
        
        # æŒ‰æ—¥æœŸèšåˆï¼ˆç”¨äºè®¡ç®—æ—¥æ”¶ç›Šç‡ï¼‰
        df['æ—¥æœŸ_ä»…'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y/%m/%d', errors='coerce')
        daily_pnl = df.groupby('æ—¥æœŸ_ä»…')['å‡€ç›ˆäº'].sum().reset_index() #groupby()æ˜¯pandasçš„ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºæŒ‰æŒ‡å®šåˆ—åˆ†ç»„ï¼Œç„¶åå¯¹æ¯ä¸ªç»„è¿›è¡Œèšåˆæ“ä½œï¼Œè¿™é‡Œæ˜¯æŒ‰'æ—¥æœŸ_ä»…'åˆ—åˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªæ—¥æœŸçš„å‡€ç›ˆäºæ€»å’Œ
        daily_pnl.columns = ['æ—¥æœŸ', 'æ—¥ç›ˆäº']
        daily_pnl = daily_pnl.sort_values('æ—¥æœŸ').reset_index(drop=True)
        daily_pnl['ç´¯è®¡æ”¶ç›Š'] = daily_pnl['æ—¥ç›ˆäº'].cumsum()
        daily_pnl['æ—¥æ”¶ç›Šç‡'] = (daily_pnl['æ—¥ç›ˆäº'] / initial_capital) * 100
        # ä¿®å¤bugï¼šæ·»åŠ ç´¯è®¡æ”¶ç›Šç‡åˆ—
        daily_pnl['ç´¯è®¡æ”¶ç›Šç‡'] = (daily_pnl['ç´¯è®¡æ”¶ç›Š'] / initial_capital) * 100
        
        # è®¡ç®—æ—¥æ”¶ç›Šç‡åºåˆ—ï¼ˆè½¬æ¢ä¸ºå°æ•°å½¢å¼ç”¨äºè®¡ç®—ï¼‰
        daily_returns_pct = daily_pnl['æ—¥æ”¶ç›Šç‡'].values / 100
        total_returns_pct = daily_pnl['ç´¯è®¡æ”¶ç›Š'].iloc[-1] / initial_capital * 100 if len(daily_pnl) > 0 else 0
        
        # è·å–åŸºå‡†æ•°æ®ï¼ˆä½¿ç”¨ç¡¬ç¼–ç æ•°æ®ï¼‰
        benchmark_returns = BENCHMARK_RETURNS_HARDCODED.copy()
        
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        if len(benchmark_returns) != len(daily_returns_pct):
            min_len = min(len(benchmark_returns), len(daily_returns_pct))
            benchmark_returns = benchmark_returns[:min_len]
            daily_returns_pct_aligned = daily_returns_pct[:min_len]
            daily_pnl_aligned = daily_pnl.iloc[:min_len].copy()
        else:
            daily_returns_pct_aligned = daily_returns_pct
            daily_pnl_aligned = daily_pnl.copy()
        
        st.success(f"âœ… äº¤æ˜“è¯¦æƒ…æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(benchmark_returns)} ä¸ªäº¤æ˜“æ—¥")
        
        # è®¡ç®—é£é™©æŒ‡æ ‡ï¼ˆä½¿ç”¨å¯¹é½åçš„daily_pnlï¼‰
        #åˆ†åˆ«è¡¨ç¤ºå¯¹é½åçš„æ—¥æ”¶ç›Šç‡åºåˆ—ã€æ€»æ”¶ç›Šç‡ã€åˆå§‹èµ„é‡‘ã€å¯¹é½åçš„æ—¥ç›ˆäºæ•°æ®å’ŒåŸºå‡†æ”¶ç›Šç‡æ•°æ®
        #è¿™5ä¸ªå‚æ•°å°±èƒ½å¤Ÿè®¡ç®—æ‰€æœ‰çš„é£é™©æŒ‡æ ‡ï¼Œè¿™é‡Œmeticsæ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«äº†æ‰€æœ‰è®¡ç®—å‡ºæ¥çš„é£é™©æŒ‡æ ‡
        metrics = calculate_risk_metrics(daily_returns_pct_aligned, total_returns_pct, initial_capital, daily_pnl_aligned, benchmark_returns)
    
    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»äº¤æ˜“ç¬”æ•°", len(df)) #st.metric()æ˜¯Streamlitä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ˜¾ç¤ºä¸€ä¸ªæŒ‡æ ‡ï¼Œè¿™é‡Œæ˜¾ç¤ºæ€»äº¤æ˜“ç¬”æ•°
    with col2:
        st.metric("äº¤æ˜“æ—¥æœŸèŒƒå›´", f"{daily_pnl['æ—¥æœŸ'].min().strftime('%Y-%m-%d')} è‡³ {daily_pnl['æ—¥æœŸ'].max().strftime('%Y-%m-%d')}")
    with col3:
        st.metric("æ€»ç›ˆäº", f"{df['å‡€ç›ˆäº'].sum():,.0f}")
    with col4:
        st.metric("åˆå§‹èµ„é‡‘", f"{initial_capital:,.0f}")
    
    st.divider()
    
    # é£é™©æŒ‡æ ‡å±•ç¤º
    st.header("ğŸ“ˆ é£é™©æŒ‡æ ‡") #st.header()æ˜¯Streamlitä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆ›å»ºä¸€ä¸ªä¸€çº§æ ‡é¢˜
    
    # å°†æŒ‡æ ‡åˆ†ä¸ºå¤šåˆ—æ˜¾ç¤º
    col1, col2, col3 = st.columns(3) #st.columns()æ˜¯Streamlitä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆ›å»ºå¤šåˆ—å¸ƒå±€ï¼Œè¿™é‡Œåˆ›å»ºäº†3åˆ—å¸ƒå±€
    
    with col1: #withæ˜¯Pythonä¸­çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºç®€åŒ–èµ„æºç®¡ç†ï¼Œè¿™é‡Œç”¨äºåœ¨col1åˆ—ä¸­æ˜¾ç¤ºå†…å®¹ï¼Œå’Œpythonä¸­çš„withä¸€æ ·ï¼Œä½†æ˜¯åœ¨streamlitä¸­ç”¨äºå¸ƒå±€ç®¡ç†
        st.subheader("æ”¶ç›ŠæŒ‡æ ‡") #st.subheader()æ˜¯Streamlitä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆ›å»ºä¸€ä¸ªäºŒçº§æ ‡é¢˜
        st.write(f"**Total Returns (ç­–ç•¥æ”¶ç›Š)**: {metrics.get('Total Returns', 0):.4f}%") #st.write()æ˜¯Streamlitä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåœ¨é¡µé¢ä¸Šæ˜¾ç¤ºæ–‡æœ¬æˆ–å˜é‡å†…å®¹
        st.write(f"**Total Annualized Returns (ç­–ç•¥å¹´åŒ–æ”¶ç›Š)**: {metrics.get('Total Annualized Returns', 0):.4f}%")
        st.write(f"**Alpha (é˜¿å°”æ³•)**: {metrics.get('Alpha', 0):.4f}%")
        st.write(f"**Beta (è´å¡”)**: {metrics.get('Beta', 0):.4f}")
        st.write(f"**AEI (æ—¥å‡è¶…é¢æ”¶ç›Š)**: {metrics.get('AEI', 0):.4f}%")
        st.write(f"**è¶…é¢æ”¶ç›Š**: {metrics.get('è¶…é¢æ”¶ç›Š', 0):.4f}%")
        st.write(f"**å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š**: {metrics.get('å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š', 0):.4f}%")
    
    with col2:
        st.subheader("é£é™©æŒ‡æ ‡")
        st.write(f"**Sharpe (å¤æ™®æ¯”ç‡)**: {metrics.get('Sharpe', 0):.4f}")
        st.write(f"**Sortino (ç´¢æè¯ºæ¯”ç‡)**: {metrics.get('Sortino', 0):.4f}")
        st.write(f"**Information Ratio (ä¿¡æ¯æ¯”ç‡)**: {metrics.get('Information Ratio', 0):.4f}")
        st.write(f"**Algorithm Volatility (ç­–ç•¥æ³¢åŠ¨ç‡)**: {metrics.get('Algorithm Volatility', 0):.4f}%")
        st.write(f"**Benchmark Volatility (åŸºå‡†æ³¢åŠ¨ç‡)**: {metrics.get('Benchmark Volatility', 0):.4f}%")
        st.write(f"**Max Drawdown (æœ€å¤§å›æ’¤)**: {metrics.get('Max Drawdown', 0):.4f}%")
        st.write(f"**Downside Risk (ä¸‹è¡Œæ³¢åŠ¨ç‡)**: {metrics.get('Downside Risk', 0):.4f}%")
    
    with col3:
        st.subheader("äº¤æ˜“ç»Ÿè®¡")
        st.write(f"**èƒœç‡**: {metrics.get('èƒœç‡', 0):.4f}%")
        st.write(f"**æ—¥èƒœç‡**: {metrics.get('æ—¥èƒœç‡', 0):.4f}%")
        st.write(f"**ç›ˆäºæ¯”**: {metrics.get('ç›ˆäºæ¯”', 0):.4f}")
        st.write(f"**è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤**: {metrics.get('è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤', 0):.4f}%")
        st.write(f"**è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡**: {metrics.get('è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡', 0):.4f}")
    
    st.divider() #st.divider()æ˜¯Streamlitä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåœ¨é¡µé¢ä¸Šæ·»åŠ ä¸€ä¸ªæ°´å¹³åˆ†å‰²çº¿ï¼Œèµ·åˆ°åˆ†éš”å†…å®¹çš„ä½œç”¨,æ‹¬å·å†…å¯ä»¥æ·»åŠ å‚æ•°æ¥å®šåˆ¶åˆ†å‰²çº¿çš„æ ·å¼ï¼Œ
                 #ä½†é€šå¸¸ä¸éœ€è¦å‚æ•°ï¼Œé»˜è®¤æ ·å¼å³å¯ã€‚æ¯”å¦‚ï¼šst.divider(color="blue", thickness=2)ä»£è¡¨æ·»åŠ ä¸€æ¡è“è‰²ã€åšåº¦ä¸º2åƒç´ çš„åˆ†å‰²çº¿ã€‚
    
    # äº¤æ˜“ä¿¡å·å›¾ï¼ˆä¸»è¦å›¾è¡¨ï¼‰
    st.header("ğŸ“Š äº¤æ˜“ä¿¡å·å›¾")
    st.info("ğŸ’¡ **äº¤æ˜“ä¿¡å·å›¾è¯´æ˜**ï¼šä¸Šå›¾æ˜¾ç¤ºä»·æ ¼èµ°åŠ¿ï¼Œç»¿è‰²â–²è¡¨ç¤ºä¹°å…¥ä¿¡å·ï¼ˆå¼€å¤šï¼‰ï¼Œçº¢è‰²â–¼è¡¨ç¤ºå–å‡ºä¿¡å·ï¼ˆå¹³å¤šï¼‰ã€‚ä¸‹å›¾æ˜¾ç¤ºæ¯ç¬”äº¤æ˜“çš„ç›ˆäºå’Œç´¯è®¡æ”¶ç›Šã€‚")
    
    fig_signals = plot_trading_signals(df) #plot_trading_signals()æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰å‡½æ•°ï¼Œç”¨äºç»˜åˆ¶äº¤æ˜“ä¿¡å·å›¾
    st.plotly_chart(fig_signals, use_container_width=True) #st.plotly_chart()æ˜¯Streamlitä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåœ¨é¡µé¢ä¸Šæ˜¾ç¤ºPlotlyå›¾è¡¨ï¼Œuse_container_width=Trueå‚æ•°è¡¨ç¤ºå›¾è¡¨å®½åº¦ä¼šè‡ªåŠ¨é€‚åº”å®¹å™¨å®½åº¦
    
    st.divider()
    
    # é£é™©åˆ†æå›¾è¡¨
    st.header("ğŸ“ˆ é£é™©åˆ†æå›¾è¡¨")
    
    # å¯¹æ•°è½´é€‰é¡¹
    use_log_scale = st.checkbox("ä½¿ç”¨å¯¹æ•°è½´æ˜¾ç¤ºç´¯è®¡æ”¶ç›Š", value=False, 
                                help="åœ¨å¯¹æ•°è½´ä¸Šï¼Œç›¸åŒçš„ç™¾åˆ†æ¯”å˜åŒ–æ˜¾ç¤ºä¸ºç›¸åŒçš„è·ç¦»ï¼Œä¾¿äºæ¯”è¾ƒä¸åŒè§„æ¨¡çš„æŠ•èµ„è¡¨ç°")
    
    # ç»˜åˆ¶å›¾è¡¨
    fig = plot_risk_charts(df, daily_pnl, metrics, use_log_scale=use_log_scale)
    st.plotly_chart(fig, use_container_width=True)
    
    # æ•°æ®è¡¨æ ¼
    with st.expander("æŸ¥çœ‹è¯¦ç»†äº¤æ˜“æ•°æ®"): #st.expander()æ˜¯Streamlitä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆ›å»ºä¸€ä¸ªå¯å±•å¼€/æŠ˜å çš„åŒºåŸŸï¼Œç”¨æˆ·å¯ä»¥ç‚¹å‡»æ ‡é¢˜æ¥å±•å¼€æˆ–æŠ˜å å†…å®¹
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
        display_cols = ['æ—¥æœŸ', 'å§”æ‰˜æ—¶é—´', 'æ ‡çš„', 'äº¤æ˜“ç±»å‹', 'æˆäº¤æ•°é‡'] 
        # æ·»åŠ ä»·æ ¼åˆ—ï¼ˆå¯èƒ½æ˜¯'æˆäº¤ä»·'æˆ–'æˆäº¤ä»·æ ¼'ï¼‰
        display_cols.append('æˆäº¤ä»·')
        display_cols.append('æˆäº¤é¢') #append()æ˜¯Pythonåˆ—è¡¨çš„æ–¹æ³•ï¼Œç”¨äºåœ¨åˆ—è¡¨æœ«å°¾æ·»åŠ ä¸€ä¸ªå…ƒç´ 
        display_cols.extend(['å¹³ä»“ç›ˆäº', 'æ‰‹ç»­è´¹', 'å‡€ç›ˆäº', 'ç´¯è®¡æ”¶ç›Š']) #extend()æ˜¯Pythonåˆ—è¡¨çš„æ–¹æ³•ï¼Œç”¨äºå°†ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼ˆå¦‚åˆ—è¡¨ã€å…ƒç»„ç­‰ï¼‰ä¸­çš„å…ƒç´ é€ä¸ªæ·»åŠ åˆ°å½“å‰åˆ—è¡¨çš„æœ«å°¾
        # åªæ˜¾ç¤ºå­˜åœ¨çš„åˆ—
        available_cols = [col for col in display_cols if col in df.columns] #columnsæ˜¯pandas DataFrameçš„ä¸€ä¸ªå±æ€§ï¼Œè¿”å›DataFrameçš„åˆ—æ ‡ç­¾åˆ—è¡¨ï¼Œè¿™é‡Œç”¨æ¥æ£€æŸ¥å“ªäº›åˆ—å­˜åœ¨äºDataFrameä¸­
        st.dataframe(df[available_cols], use_container_width=True) #st.dataframe()æ˜¯Streamlitä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåœ¨é¡µé¢ä¸Šæ˜¾ç¤ºä¸€ä¸ªå¯æ»šåŠ¨çš„æ•°æ®è¡¨æ ¼
    
    with st.expander("æŸ¥çœ‹æ—¥åº¦æ±‡æ€»æ•°æ®"):
        st.dataframe(daily_pnl, use_container_width=True) #use_container_width=Trueå‚æ•°è¡¨ç¤ºè¡¨æ ¼å®½åº¦ä¼šè‡ªåŠ¨é€‚åº”å®¹å™¨å®½åº¦

if __name__ == "__main__": 
    main()
