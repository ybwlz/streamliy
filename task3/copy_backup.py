import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
import warnings
warnings.filterwarnings('ignore')

# ========== åŸºå‡†æ•°æ® ==========
# è¿™æ˜¯æ ¹æ®jiaoyi.csvçš„æ—¥æœŸèŒƒå›´è·å–çš„é»„é‡‘æœŸè´§åŸºå‡†æ”¶ç›Šç‡æ•°æ®ï¼ˆä½¿ç”¨AU0ä¸»åŠ›è¿ç»­åˆçº¦ï¼‰
# æ•°æ®æ ¼å¼ï¼šä¸äº¤æ˜“æ—¥æœŸå¯¹é½çš„æ—¥æ”¶ç›Šç‡åºåˆ—ï¼ˆå°æ•°å½¢å¼ï¼Œå¦‚0.01è¡¨ç¤º1%ï¼‰
# åŸºå‡†æ•°æ®æ—¥æœŸèŒƒå›´: 2024-01-04 åˆ° 2025-04-28ï¼Œå…±71ä¸ªäº¤æ˜“æ—¥
# æ³¨æ„ï¼šç¬¬ä¸€ä¸ªå€¼ä¸º0ï¼Œå› ä¸ºç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥æ²¡æœ‰å‰ä¸€å¤©çš„ä»·æ ¼æ•°æ®
# åŸºå‡†æ•°æ®æ¥æºï¼šakshareè·å–çš„AU0é»„é‡‘ä¸»åŠ›è¿ç»­åˆçº¦ï¼Œæ•´ä¸ªæœŸé—´ï¼ˆ315ä¸ªè¿ç»­äº¤æ˜“æ—¥ï¼‰æ€»æ”¶ç›Šç‡61.95%
# å¯¹é½è¯´æ˜ï¼šä½¿ç”¨æ•´ä¸ªæœŸé—´çš„è¿ç»­åŸºå‡†æ•°æ®ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥ä½¿ç”¨ä»ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥åˆ°è¯¥äº¤æ˜“æ—¥ä¹‹é—´çš„ç´¯è®¡åŸºå‡†æ”¶ç›Šç‡
# å¯¹é½åçš„åŸºå‡†æ•°æ®æ€»æ”¶ç›Šç‡ï¼š62.56%ï¼ˆä¸è¿ç»­åŸºå‡†æ€»æ”¶ç›Šç‡61.95%éå¸¸æ¥è¿‘ï¼Œå·®å¼‚0.60%ï¼‰
BENCHMARK_RETURNS_HARDCODED = np.array([
    0.00000000, 0.00079190, -0.00283192, 0.00062646, -0.00488334, 0.01673517, -0.00858050, -0.00124828, 0.00283298, -0.00029081,
    0.05290060, 0.00280223, 0.09260863, 0.02121681, -0.00261023, -0.03656811, 0.00998458, 0.00214436, -0.00569398, 0.01148964,
    -0.00025243, 0.00941423, -0.00982669, -0.00476362, -0.00638190, 0.00080286, 0.00291715, 0.00199971, -0.01048659, 0.01298130,
    0.00582827, 0.00906964, 0.00841745, -0.00010611, -0.00597807, 0.00882531, 0.00134044, 0.01490119, -0.00045123, -0.00888981,
    -0.00455485, 0.05490831, -0.01811751, 0.00363599, 0.02133062, 0.05363832, -0.00934462, -0.00898812, -0.02041470, -0.00925865,
    0.00815639, 0.00959712, -0.00528826, 0.01063275, -0.00196863, -0.00737268, 0.00824185, -0.00216478, 0.01868342, 0.08521933,
    0.01051522, -0.02394203, 0.00074241, 0.01249295, 0.03599062, 0.00472445, 0.01109390, 0.06441282, 0.02595364, 0.00372316,
    -0.00909553
])

BENCHMARK_AVAILABLE = True

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç­–ç•¥é£é™©åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# åŠ è½½äº¤æ˜“æ•°æ®ï¼ˆä½¿ç”¨GBKç¼–ç ï¼‰
@st.cache_data
def load_trade_data(filename='jiaoyi.csv'):
    """åŠ è½½äº¤æ˜“æ•°æ®"""
    import os
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
    possible_paths = [
        os.path.join(script_dir, filename),  # è„šæœ¬æ‰€åœ¨ç›®å½•
        filename,  # å½“å‰å·¥ä½œç›®å½•
        os.path.join('.', filename),  # å½“å‰ç›®å½•
        os.path.join('task3', filename),  # task3å­ç›®å½•
    ]
    
    for file_path in possible_paths:
        try:
            if os.path.exists(file_path):
                df = pd.read_csv(file_path, encoding='gbk')
                return df
        except Exception as e:
            continue
    
    # å¦‚æœæ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    st.error(f"æ— æ³•æ‰¾åˆ°æ–‡ä»¶: {filename}")
    st.info("**è°ƒè¯•ä¿¡æ¯ï¼š**")
    st.info(f"- è„šæœ¬æ‰€åœ¨ç›®å½•: {script_dir}")
    st.info(f"- å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    st.info(f"- å°è¯•çš„è·¯å¾„: {', '.join(possible_paths)}")
    
    # åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    try:
        current_files = os.listdir('.')
        st.info(f"- å½“å‰ç›®å½•æ–‡ä»¶: {', '.join([f for f in current_files if f.endswith('.csv')][:5])}")
    except:
        pass
    
    try:
        script_files = os.listdir(script_dir)
        st.info(f"- è„šæœ¬ç›®å½•æ–‡ä»¶: {', '.join([f for f in script_files if f.endswith('.csv')][:5])}")
    except:
        pass
    
    return None

# æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
def preprocess_data(df):
    """é¢„å¤„ç†äº¤æ˜“æ•°æ®"""
    df = df.copy()
    
    # åˆå¹¶æ—¥æœŸå’Œæ—¶é—´
    try:
        df['æ—¥æœŸæ—¶é—´'] = pd.to_datetime(df['æ—¥æœŸ'].astype(str) + ' ' + df['å§”æ‰˜æ—¶é—´'].astype(str), 
                                      format='%Y/%m/%d %H:%M:%S', errors='coerce')
    except:
        df['æ—¥æœŸæ—¶é—´'] = pd.to_datetime(df['æ—¥æœŸ'].astype(str) + ' ' + df['å§”æ‰˜æ—¶é—´'].astype(str), errors='coerce')
    
    df = df.sort_values('æ—¥æœŸæ—¶é—´').reset_index(drop=True)
    
    # è½¬æ¢æ•°æ®ç±»å‹
    # æˆäº¤æ•°é‡ï¼ˆå¤„ç†"æ‰‹"å•ä½ï¼‰
    if 'æˆäº¤æ•°é‡' in df.columns:
        if df['æˆäº¤æ•°é‡'].dtype == 'object':
            df['æˆäº¤æ•°é‡'] = df['æˆäº¤æ•°é‡'].astype(str).str.replace('æ‰‹', '').str.replace(',', '').str.strip()
            df['æˆäº¤æ•°é‡'] = pd.to_numeric(df['æˆäº¤æ•°é‡'], errors='coerce')
        else:
            df['æˆäº¤æ•°é‡'] = pd.to_numeric(df['æˆäº¤æ•°é‡'], errors='coerce')
    
    # æˆäº¤ä»·æ ¼ï¼ˆåˆ—åå¯èƒ½æ˜¯'æˆäº¤ä»·'ï¼‰
    price_col = 'æˆäº¤ä»·' if 'æˆäº¤ä»·' in df.columns else 'æˆäº¤ä»·æ ¼'
    if price_col in df.columns:
        if df[price_col].dtype == 'object':
            df[price_col] = df[price_col].astype(str).str.replace(',', '').str.strip()
        df[price_col] = pd.to_numeric(df[price_col], errors='coerce')
        # ç»Ÿä¸€åˆ—åä¸º'æˆäº¤ä»·æ ¼'
        if price_col != 'æˆäº¤ä»·æ ¼':
            df['æˆäº¤ä»·æ ¼'] = df[price_col]
    
    # æˆäº¤é‡‘é¢ï¼ˆåˆ—åå¯èƒ½æ˜¯'æˆäº¤é¢'ï¼‰
    amount_col = 'æˆäº¤é¢' if 'æˆäº¤é¢' in df.columns else 'æˆäº¤é‡‘é¢'
    if amount_col in df.columns:
        if df[amount_col].dtype == 'object':
            df[amount_col] = df[amount_col].astype(str).str.replace(',', '').str.strip()
        df[amount_col] = pd.to_numeric(df[amount_col], errors='coerce')
        # ç»Ÿä¸€åˆ—åä¸º'æˆäº¤é‡‘é¢'
        if amount_col != 'æˆäº¤é‡‘é¢':
            df['æˆäº¤é‡‘é¢'] = df[amount_col]
    
    # å¹³ä»“ç›ˆäºï¼ˆå¤„ç†"-"è¡¨ç¤º0çš„æƒ…å†µï¼‰
    if df['å¹³ä»“ç›ˆäº'].dtype == 'object':
        df['å¹³ä»“ç›ˆäº'] = df['å¹³ä»“ç›ˆäº'].astype(str).str.replace(',', '').str.strip()
        df['å¹³ä»“ç›ˆäº'] = df['å¹³ä»“ç›ˆäº'].replace(['-', ''], '0')
    df['å¹³ä»“ç›ˆäº'] = pd.to_numeric(df['å¹³ä»“ç›ˆäº'], errors='coerce').fillna(0)
    
    # æ‰‹ç»­è´¹
    if df['æ‰‹ç»­è´¹'].dtype == 'object':
        df['æ‰‹ç»­è´¹'] = df['æ‰‹ç»­è´¹'].astype(str).str.replace(',', '').str.strip()
        df['æ‰‹ç»­è´¹'] = df['æ‰‹ç»­è´¹'].replace(['-', ''], '0')
    df['æ‰‹ç»­è´¹'] = pd.to_numeric(df['æ‰‹ç»­è´¹'], errors='coerce').fillna(0)
    
    # è®¡ç®—æ¯ç¬”äº¤æ˜“çš„å‡€ç›ˆäºï¼ˆå¹³ä»“ç›ˆäº - æ‰‹ç»­è´¹ï¼‰
    df['å‡€ç›ˆäº'] = df['å¹³ä»“ç›ˆäº'] - df['æ‰‹ç»­è´¹']
    
    return df

# è®¡ç®—é£é™©æŒ‡æ ‡
def calculate_risk_metrics(daily_returns, total_returns, initial_capital, daily_pnl, benchmark_returns=None):
    """è®¡ç®—å„ç§é£é™©æŒ‡æ ‡"""
    metrics = {}
    
    # ç¡®ä¿daily_returnsæ˜¯æ•°ç»„
    if isinstance(daily_returns, pd.Series):
        daily_returns = daily_returns.values
    
    # è¿‡æ»¤NaNå€¼
    daily_returns = daily_returns[~np.isnan(daily_returns)]
    
    if len(daily_returns) == 0:
        return {}
    
    # Total Returns ç­–ç•¥æ”¶ç›Šï¼ˆç™¾åˆ†æ¯”ï¼‰
    metrics['Total Returns'] = total_returns
    
    # Total Annualized Returns ç­–ç•¥å¹´åŒ–æ”¶ç›Š
    trading_days = len(daily_returns)
    if trading_days > 0:
        # è®¡ç®—å®é™…äº¤æ˜“å¤©æ•°
        date_range = (daily_pnl['æ—¥æœŸ'].max() - daily_pnl['æ—¥æœŸ'].min()).days
        years = date_range / 365.25 if date_range > 0 else trading_days / 252
        if years > 0:
            metrics['Total Annualized Returns'] = ((1 + total_returns / 100) ** (1 / years) - 1) * 100
        else:
            metrics['Total Annualized Returns'] = 0
    else:
        metrics['Total Annualized Returns'] = 0
    
    # Algorithm Volatility ç­–ç•¥æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–ï¼‰
    if len(daily_returns) > 1:
        metrics['Algorithm Volatility'] = np.std(daily_returns) * np.sqrt(252) * 100
    else:
        metrics['Algorithm Volatility'] = 0
    
    # Benchmark Volatility åŸºå‡†æ³¢åŠ¨ç‡ï¼ˆå¦‚æœæœ‰åŸºå‡†æ•°æ®ï¼‰
    if benchmark_returns is not None and len(benchmark_returns) > 1:
        metrics['Benchmark Volatility'] = np.std(benchmark_returns) * np.sqrt(252) * 100
    else:
        metrics['Benchmark Volatility'] = 0
    
    # Sharpe å¤æ™®æ¯”ç‡ï¼ˆå‡è®¾æ— é£é™©åˆ©ç‡ä¸º0ï¼‰
    if metrics['Algorithm Volatility'] > 0:
        metrics['Sharpe'] = metrics['Total Annualized Returns'] / metrics['Algorithm Volatility']
    else:
        metrics['Sharpe'] = 0
    
    # Sortino ç´¢æè¯ºæ¯”ç‡ï¼ˆåªè€ƒè™‘ä¸‹è¡Œæ³¢åŠ¨ï¼‰
    downside_returns = daily_returns[daily_returns < 0]
    if len(downside_returns) > 1:
        downside_std = np.std(downside_returns) * np.sqrt(252) * 100
        metrics['Downside Risk'] = downside_std
        if downside_std > 0:
            metrics['Sortino'] = metrics['Total Annualized Returns'] / downside_std
        else:
            metrics['Sortino'] = 0
    else:
        metrics['Downside Risk'] = 0
        metrics['Sortino'] = 0
    
    # Max Drawdown æœ€å¤§å›æ’¤
    # ä½¿ç”¨å¤åˆ©è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡ï¼š(1 + r1) * (1 + r2) * ... - 1
    cumulative_returns = np.cumprod(1 + daily_returns) - 1
    running_max = np.maximum.accumulate(cumulative_returns)
    drawdown = cumulative_returns - running_max
    # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
    metrics['Max Drawdown'] = np.min(drawdown) * 100 if len(drawdown) > 0 else 0
    
    # Alpha å’Œ Betaï¼ˆå¦‚æœæœ‰åŸºå‡†æ•°æ®ï¼‰
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 1 and len(benchmark_returns_clean) > 1:
            # è®¡ç®—åæ–¹å·®å’Œæ–¹å·®
            covariance = np.cov(daily_returns_clean, benchmark_returns_clean)[0, 1]
            benchmark_variance = np.var(benchmark_returns_clean, ddof=0)
            
            if benchmark_variance > 1e-10:  # é¿å…é™¤é›¶
                metrics['Beta'] = covariance / benchmark_variance
                
                # Alpha = (ç­–ç•¥å¹³å‡æ—¥æ”¶ç›Šç‡ - Beta * åŸºå‡†å¹³å‡æ—¥æ”¶ç›Šç‡) * 252 * 100
                # daily_returns å’Œ benchmark_returns éƒ½æ˜¯å°æ•°å½¢å¼ï¼ˆ0.01è¡¨ç¤º1%ï¼‰
                strategy_mean_daily = np.mean(daily_returns_clean)
                benchmark_mean_daily = np.mean(benchmark_returns_clean)
                alpha_daily = strategy_mean_daily - metrics['Beta'] * benchmark_mean_daily
                # å¹´åŒ–Alphaï¼ˆè½¬æ¢ä¸ºç™¾åˆ†æ¯”ï¼‰
                metrics['Alpha'] = alpha_daily * 252 * 100
                
                # éªŒè¯Alphaå€¼çš„åˆç†æ€§ï¼ˆé€šå¸¸åº”è¯¥åœ¨-100%åˆ°+100%ä¹‹é—´ï¼‰
                if abs(metrics['Alpha']) > 200:
                    print(f"è­¦å‘Š: Alphaå€¼å¼‚å¸¸é«˜ ({metrics['Alpha']:.2f}%)ï¼Œè¯·æ£€æŸ¥åŸºå‡†æ•°æ®æ˜¯å¦æ­£ç¡®")
                    print(f"  ç­–ç•¥å¹³å‡æ—¥æ”¶ç›Šç‡: {strategy_mean_daily*100:.4f}%")
                    print(f"  åŸºå‡†å¹³å‡æ—¥æ”¶ç›Šç‡: {benchmark_mean_daily*100:.4f}%")
                    print(f"  Beta: {metrics['Beta']:.4f}")
            else:
                metrics['Beta'] = 0
                metrics['Alpha'] = 0
            
            # Information Ratio ä¿¡æ¯æ¯”ç‡
            excess_returns = daily_returns_clean - benchmark_returns_clean
            if len(excess_returns) > 1:
                tracking_error = np.std(excess_returns, ddof=0) * np.sqrt(252) * 100
                excess_return_mean = np.mean(excess_returns)
                excess_return_annual = excess_return_mean * 252 * 100
                
                if tracking_error > 1e-10:
                    metrics['Information Ratio'] = excess_return_annual / tracking_error
                else:
                    metrics['Information Ratio'] = 0
            else:
                metrics['Information Ratio'] = 0
        else:
            metrics['Beta'] = 0
            metrics['Alpha'] = 0
            metrics['Information Ratio'] = 0
    else:
        metrics['Alpha'] = 0
        metrics['Beta'] = 0
        metrics['Information Ratio'] = 0
    
    # èƒœç‡ï¼ˆæŒ‰äº¤æ˜“ç¬”æ•°ï¼‰
    winning_trades = (daily_returns > 0).sum()
    total_trades = len(daily_returns)
    metrics['èƒœç‡'] = (winning_trades / total_trades * 100) if total_trades > 0 else 0
    
    # æ—¥èƒœç‡ï¼ˆæŒ‰æ—¥ç»Ÿè®¡ï¼‰ï¼šå½“æ—¥ç­–ç•¥æ”¶ç›Šè·‘èµ¢å½“æ—¥åŸºå‡†æ”¶ç›Šçš„å¤©æ•° / æ€»äº¤æ˜“æ—¥æ•°
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            # ç»Ÿè®¡ç­–ç•¥æ”¶ç›Šè·‘èµ¢åŸºå‡†æ”¶ç›Šçš„å¤©æ•°
            winning_days = (daily_returns_clean > benchmark_returns_clean).sum()
            total_days = len(daily_returns_clean)
            metrics['æ—¥èƒœç‡'] = (winning_days / total_days * 100) if total_days > 0 else 0
        else:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„åŸºå‡†æ•°æ®ï¼Œå›é€€åˆ°åŸæ¥çš„è®¡ç®—æ–¹æ³•
            winning_days = (daily_pnl['æ—¥ç›ˆäº'] > 0).sum()
            total_days = len(daily_pnl)
            metrics['æ—¥èƒœç‡'] = (winning_days / total_days * 100) if total_days > 0 else 0
    else:
        # å¦‚æœæ²¡æœ‰åŸºå‡†æ•°æ®ï¼Œä½¿ç”¨åŸæ¥çš„è®¡ç®—æ–¹æ³•ï¼ˆæ—¥ç›ˆäº>0çš„å¤©æ•°ï¼‰
        winning_days = (daily_pnl['æ—¥ç›ˆäº'] > 0).sum()
        total_days = len(daily_pnl)
        metrics['æ—¥èƒœç‡'] = (winning_days / total_days * 100) if total_days > 0 else 0
    
    # ç›ˆäºæ¯”
    if winning_trades > 0 and (total_trades - winning_trades) > 0:
        avg_win = daily_returns[daily_returns > 0].mean()
        avg_loss = abs(daily_returns[daily_returns < 0].mean())
        metrics['ç›ˆäºæ¯”'] = avg_win / avg_loss if avg_loss > 0 else 0
    else:
        metrics['ç›ˆäºæ¯”'] = 0
    
    # AEI æ—¥å‡è¶…é¢æ”¶ç›Šï¼ˆå¦‚æœæœ‰åŸºå‡†ï¼‰
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            excess_returns = daily_returns_clean - benchmark_returns_clean
            metrics['AEI'] = np.mean(excess_returns) * 100
        else:
            metrics['AEI'] = 0
    else:
        metrics['AEI'] = 0
    
    # è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            excess_returns = daily_returns_clean - benchmark_returns_clean
            # ä½¿ç”¨å¤åˆ©è®¡ç®—ç´¯è®¡è¶…é¢æ”¶ç›Šç‡
            excess_cumulative = np.cumprod(1 + excess_returns) - 1
            excess_running_max = np.maximum.accumulate(excess_cumulative)
            excess_drawdown = excess_cumulative - excess_running_max
            # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            metrics['è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤'] = np.min(excess_drawdown) * 100 if len(excess_drawdown) > 0 else 0
        else:
            metrics['è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤'] = 0
    else:
        metrics['è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤'] = 0
    
    # è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 1:
            excess_returns = daily_returns_clean - benchmark_returns_clean
            excess_vol = np.std(excess_returns, ddof=0) * np.sqrt(252) * 100
            excess_mean = np.mean(excess_returns) * 252 * 100
            metrics['è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡'] = excess_mean / excess_vol if excess_vol > 1e-10 else 0
        else:
            metrics['è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡'] = 0
    else:
        metrics['è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡'] = 0
    
    # è¶…é¢æ”¶ç›Šï¼ˆé™¤æ³•ç‰ˆï¼‰- (ç­–ç•¥æ€»æ”¶ç›Šç‡ / åŸºå‡†æ€»æ”¶ç›Šç‡ - 1) * 100
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            # ä½¿ç”¨å¤åˆ©è®¡ç®—æ€»æ”¶ç›Šç‡ï¼š(1 + r1) * (1 + r2) * ... - 1
            strategy_total = np.prod(1 + daily_returns_clean) - 1
            benchmark_total = np.prod(1 + benchmark_returns_clean) - 1
            
            if abs(benchmark_total) > 1e-10:
                # è¶…é¢æ”¶ç›Š = (ç­–ç•¥æ€»æ”¶ç›Š / åŸºå‡†æ€»æ”¶ç›Š - 1) * 100
                metrics['è¶…é¢æ”¶ç›Š'] = (strategy_total / benchmark_total - 1) * 100
            else:
                metrics['è¶…é¢æ”¶ç›Š'] = 0
        else:
            metrics['è¶…é¢æ”¶ç›Š'] = 0
    else:
        metrics['è¶…é¢æ”¶ç›Š'] = 0
    
    # å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š
    # è®¡ç®—æ–¹æ³•ï¼šlog(1 + ç­–ç•¥æ€»æ”¶ç›Šç‡) - log(1 + åŸºå‡†æ€»æ”¶ç›Šç‡)
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_len = min(len(daily_returns), len(benchmark_returns))
        daily_returns_aligned = daily_returns[:min_len]
        benchmark_returns_aligned = benchmark_returns[:min_len]
        
        # è¿‡æ»¤NaNå€¼å’Œæ— ç©·å€¼
        valid_mask = ~(np.isnan(daily_returns_aligned) | np.isnan(benchmark_returns_aligned) | 
                      np.isinf(daily_returns_aligned) | np.isinf(benchmark_returns_aligned))
        daily_returns_clean = daily_returns_aligned[valid_mask]
        benchmark_returns_clean = benchmark_returns_aligned[valid_mask]
        
        if len(daily_returns_clean) > 0:
            # ä½¿ç”¨å¤åˆ©è®¡ç®—æ€»æ”¶ç›Šç‡ï¼š(1 + r1) * (1 + r2) * ... - 1
            strategy_total = np.prod(1 + daily_returns_clean) - 1
            benchmark_total = np.prod(1 + benchmark_returns_clean) - 1
            # ä½¿ç”¨log1pé¿å…log(0)çš„é—®é¢˜
            log_excess = np.log1p(strategy_total) - np.log1p(benchmark_total)
            metrics['å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š'] = log_excess * 100
        else:
            metrics['å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š'] = 0
    else:
        metrics['å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š'] = 0
    
    return metrics

# ç»˜åˆ¶äº¤æ˜“ä¿¡å·å›¾
def plot_trading_signals(df):
    """
    ç»˜åˆ¶äº¤æ˜“ä¿¡å·å›¾ï¼Œæ˜¾ç¤ºä»·æ ¼èµ°åŠ¿å’Œä¹°å–ä¿¡å·ç‚¹
    """
    # åˆ›å»ºå­å›¾ï¼šä»·æ ¼èµ°åŠ¿ + ç´¯è®¡æ”¶ç›Š
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('äº¤æ˜“ä¿¡å·å›¾ï¼ˆä»·æ ¼èµ°åŠ¿ï¼‰', 'ç´¯è®¡æ”¶ç›Šæ›²çº¿'),
        vertical_spacing=0.1,
        row_heights=[0.6, 0.4]
    )
    
    # æŒ‰æ—¥æœŸæ—¶é—´æ’åº
    df_sorted = df.sort_values('æ—¥æœŸæ—¶é—´').reset_index(drop=True)
    
    # 1. ä»·æ ¼èµ°åŠ¿å›¾ï¼ˆä¸»å›¾ï¼‰
    fig.add_trace(
        go.Scatter(
            x=df_sorted['æ—¥æœŸæ—¶é—´'],
            y=df_sorted['æˆäº¤ä»·æ ¼'],
            mode='lines',
            name='æˆäº¤ä»·æ ¼',
            line=dict(color='#1f77b4', width=1.5),
            hovertemplate='æ—¶é—´: %{x}<br>ä»·æ ¼: %{y:.2f}<extra></extra>'
        ),
        row=1, col=1
    )
    
    # æ ‡è®°ä¹°å…¥ä¿¡å·ï¼ˆå¼€å¤šï¼‰
    buy_signals = df_sorted[df_sorted['äº¤æ˜“ç±»å‹'].str.contains('å¼€å¤š', na=False)]
    if len(buy_signals) > 0:
        fig.add_trace(
            go.Scatter(
                x=buy_signals['æ—¥æœŸæ—¶é—´'],
                y=buy_signals['æˆäº¤ä»·æ ¼'],
                mode='markers',
                name='ä¹°å…¥ä¿¡å·ï¼ˆå¼€å¤šï¼‰',
                marker=dict(
                    symbol='triangle-up',
                    size=12,
                    color='green',
                    line=dict(width=2, color='darkgreen')
                ),
                hovertemplate='ä¹°å…¥æ—¶é—´: %{x}<br>ä»·æ ¼: %{y:.2f}<br>æ•°é‡: %{customdata}æ‰‹<extra></extra>',
                customdata=buy_signals['æˆäº¤æ•°é‡']
            ),
            row=1, col=1
        )
    
    # æ ‡è®°å–å‡ºä¿¡å·ï¼ˆå¹³å¤šï¼‰
    sell_signals = df_sorted[df_sorted['äº¤æ˜“ç±»å‹'].str.contains('å¹³å¤š', na=False)]
    if len(sell_signals) > 0:
        fig.add_trace(
            go.Scatter(
                x=sell_signals['æ—¥æœŸæ—¶é—´'],
                y=sell_signals['æˆäº¤ä»·æ ¼'],
                mode='markers',
                name='å–å‡ºä¿¡å·ï¼ˆå¹³å¤šï¼‰',
                marker=dict(
                    symbol='triangle-down',
                    size=12,
                    color='red',
                    line=dict(width=2, color='darkred')
                ),
                hovertemplate='å–å‡ºæ—¶é—´: %{x}<br>ä»·æ ¼: %{y:.2f}<br>ç›ˆäº: %{customdata:.0f}<extra></extra>',
                customdata=sell_signals['å¹³ä»“ç›ˆäº']
            ),
            row=1, col=1
        )
    
    # 2. ç´¯è®¡æ”¶ç›Šæ›²çº¿ï¼ˆå‰¯å›¾ï¼‰
    df_sorted['ç´¯è®¡æ”¶ç›Š'] = df_sorted['å‡€ç›ˆäº'].cumsum()
    colors_profit = ['green' if x >= 0 else 'red' for x in df_sorted['å‡€ç›ˆäº']]
    
    fig.add_trace(
        go.Bar(
            x=df_sorted['æ—¥æœŸæ—¶é—´'],
            y=df_sorted['å‡€ç›ˆäº'],
            name='å•ç¬”ç›ˆäº',
            marker_color=colors_profit,
            hovertemplate='æ—¶é—´: %{x}<br>ç›ˆäº: %{y:,.0f}<extra></extra>'
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=df_sorted['æ—¥æœŸæ—¶é—´'],
            y=df_sorted['ç´¯è®¡æ”¶ç›Š'],
            mode='lines',
            name='ç´¯è®¡æ”¶ç›Š',
            line=dict(color='blue', width=2),
            hovertemplate='æ—¶é—´: %{x}<br>ç´¯è®¡æ”¶ç›Š: %{y:,.0f}<extra></extra>'
        ),
        row=2, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    fig.add_hline(y=0, line_dash="dash", line_color="gray", row=2, col=1)
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        height=800,
        title_text="äº¤æ˜“ä¿¡å·å›¾",
        title_x=0.5,
        showlegend=True,
        hovermode='x unified',
        template='plotly_white'
    )
    
    # æ›´æ–°Yè½´æ ‡ç­¾
    fig.update_yaxes(title_text="ä»·æ ¼", row=1, col=1)
    fig.update_yaxes(title_text="ç›ˆäº", row=2, col=1)
    
    # æ›´æ–°Xè½´
    fig.update_xaxes(title_text="æ—¶é—´", row=2, col=1)
    
    return fig

# ç»˜åˆ¶é£é™©æŒ‡æ ‡å›¾è¡¨
def plot_risk_charts(df, daily_pnl, metrics, use_log_scale=False):
    """
    ä½¿ç”¨Plotlyç»˜åˆ¶é£é™©æŒ‡æ ‡å›¾è¡¨
    
    å‚æ•°:
    - use_log_scale: æ˜¯å¦ä½¿ç”¨å¯¹æ•°è½´ï¼ˆå¯¹æ•°è½´è¯´æ˜ï¼šåœ¨å¯¹æ•°è½´ä¸Šï¼Œç›¸åŒçš„ç™¾åˆ†æ¯”å˜åŒ–æ˜¾ç¤ºä¸ºç›¸åŒçš„è·ç¦»ï¼Œ
                      ä¾¿äºæ¯”è¾ƒä¸åŒè§„æ¨¡çš„æŠ•èµ„è¡¨ç°ã€‚å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š = log(1+ç­–ç•¥æ”¶ç›Š) - log(1+åŸºå‡†æ”¶ç›Š)ï¼‰
    """
    
    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=4, cols=1,
        subplot_titles=('ç´¯è®¡æ”¶ç›Šæ›²çº¿', 'æ—¥ç›ˆäºåˆ†å¸ƒ', 'å›æ’¤æ›²çº¿', 'ç´¯è®¡æ”¶ç›Šç‡æ›²çº¿'),
        vertical_spacing=0.06,
        row_heights=[0.35, 0.2, 0.2, 0.25]
    )
    
    # 1. ç´¯è®¡æ”¶ç›Šæ›²çº¿ï¼ˆä¸»å›¾ï¼‰
    y_data = daily_pnl['ç´¯è®¡æ”¶ç›Š']
    if use_log_scale and (y_data > 0).all():
        y_data = np.log1p(y_data - y_data.min() + 1)
        yaxis_title = "ç´¯è®¡æ”¶ç›Š (å¯¹æ•°è½´)"
    else:
        yaxis_title = "ç´¯è®¡æ”¶ç›Š"
    
    fig.add_trace(
        go.Scatter(
            x=daily_pnl['æ—¥æœŸ'],
            y=y_data,
            mode='lines',
            name='ç´¯è®¡æ”¶ç›Š',
            line=dict(color='#1f77b4', width=2),
            hovertemplate='æ—¥æœŸ: %{x}<br>ç´¯è®¡æ”¶ç›Š: %{y:,.0f}<extra></extra>'
        ),
        row=1, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    if not use_log_scale:
        fig.add_hline(y=0, line_dash="dash", line_color="gray", row=1, col=1)
    
    # 2. æ—¥ç›ˆäºåˆ†å¸ƒ
    colors = ['green' if x > 0 else 'red' for x in daily_pnl['æ—¥ç›ˆäº']]
    fig.add_trace(
        go.Bar(
            x=daily_pnl['æ—¥æœŸ'],
            y=daily_pnl['æ—¥ç›ˆäº'],
            name='æ—¥ç›ˆäº',
            marker_color=colors,
            hovertemplate='æ—¥æœŸ: %{x}<br>æ—¥ç›ˆäº: %{y:,.0f}<extra></extra>'
        ),
        row=2, col=1
    )
    
    # 3. å›æ’¤æ›²çº¿
    cumulative = daily_pnl['ç´¯è®¡æ”¶ç›Š'].values
    running_max = np.maximum.accumulate(cumulative)
    drawdown = cumulative - running_max
    
    fig.add_trace(
        go.Scatter(
            x=daily_pnl['æ—¥æœŸ'],
            y=drawdown,
            mode='lines',
            name='å›æ’¤',
            fill='tozeroy',
            fillcolor='rgba(255,0,0,0.3)',
            line=dict(color='red', width=1),
            hovertemplate='æ—¥æœŸ: %{x}<br>å›æ’¤: %{y:,.0f}<extra></extra>'
        ),
        row=3, col=1
    )
    
    # 4. ç´¯è®¡æ”¶ç›Šç‡æ›²çº¿
    fig.add_trace(
        go.Scatter(
            x=daily_pnl['æ—¥æœŸ'],
            y=daily_pnl['ç´¯è®¡æ”¶ç›Šç‡'],
            mode='lines',
            name='ç´¯è®¡æ”¶ç›Šç‡',
            line=dict(color='green', width=2),
            hovertemplate='æ—¥æœŸ: %{x}<br>ç´¯è®¡æ”¶ç›Šç‡: %{y:.2f}%<extra></extra>'
        ),
        row=4, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    fig.add_hline(y=0, line_dash="dash", line_color="gray", row=4, col=1)
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        height=1200,
        title_text="ç­–ç•¥é£é™©åˆ†æå›¾è¡¨",
        title_x=0.5,
        showlegend=True,
        hovermode='x unified',
        template='plotly_white'
    )
    
    # æ›´æ–°Yè½´æ ‡ç­¾
    fig.update_yaxes(title_text=yaxis_title, row=1, col=1)
    fig.update_yaxes(title_text="æ—¥ç›ˆäº", row=2, col=1)
    fig.update_yaxes(title_text="å›æ’¤", row=3, col=1)
    fig.update_yaxes(title_text="ç´¯è®¡æ”¶ç›Šç‡ (%)", row=4, col=1)
    
    # æ›´æ–°Xè½´
    fig.update_xaxes(title_text="æ—¥æœŸ", row=4, col=1)
    
    # å¦‚æœä½¿ç”¨å¯¹æ•°è½´ï¼Œè®¾ç½®yè½´ç±»å‹
    if use_log_scale:
        fig.update_yaxes(type="log", row=1, col=1)
    
    return fig

# Streamlitä¸»ç•Œé¢
def main():
    st.title("ğŸ“Š ç­–ç•¥é£é™©åˆ†æç³»ç»Ÿ")
    
    # åŠ è½½æ•°æ®
    df = load_trade_data('jiaoyi.csv')
    
    if df is None:
        st.error("æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ jiaoyi.csv æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        return
    
    # æ•°æ®é¢„å¤„ç†
    with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
        df = preprocess_data(df)
        
        # è®¡ç®—ç´¯è®¡æ”¶ç›Š
        df['ç´¯è®¡æ”¶ç›Š'] = df['å‡€ç›ˆäº'].cumsum()
        
        # è®¡ç®—åˆå§‹èµ„é‡‘ï¼ˆä½¿ç”¨ç¬¬ä¸€ç¬”äº¤æ˜“çš„æˆäº¤é‡‘é¢ä½œä¸ºå‚è€ƒï¼‰
        initial_capital = abs(df['æˆäº¤é‡‘é¢'].iloc[0]) if len(df) > 0 and df['æˆäº¤é‡‘é¢'].iloc[0] != 0 else 1000000
        df['ç´¯è®¡æ”¶ç›Šç‡'] = (df['ç´¯è®¡æ”¶ç›Š'] / initial_capital) * 100
        
        # æŒ‰æ—¥æœŸèšåˆï¼ˆç”¨äºè®¡ç®—æ—¥æ”¶ç›Šç‡ï¼‰
        df['æ—¥æœŸ_ä»…'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y/%m/%d', errors='coerce')
        daily_pnl = df.groupby('æ—¥æœŸ_ä»…')['å‡€ç›ˆäº'].sum().reset_index()
        daily_pnl.columns = ['æ—¥æœŸ', 'æ—¥ç›ˆäº']
        daily_pnl = daily_pnl.sort_values('æ—¥æœŸ').reset_index(drop=True)
        daily_pnl['ç´¯è®¡æ”¶ç›Š'] = daily_pnl['æ—¥ç›ˆäº'].cumsum()
        daily_pnl['æ—¥æ”¶ç›Šç‡'] = (daily_pnl['æ—¥ç›ˆäº'] / initial_capital) * 100
        # ä¿®å¤bugï¼šæ·»åŠ ç´¯è®¡æ”¶ç›Šç‡åˆ—
        daily_pnl['ç´¯è®¡æ”¶ç›Šç‡'] = (daily_pnl['ç´¯è®¡æ”¶ç›Š'] / initial_capital) * 100
        
        # è®¡ç®—æ—¥æ”¶ç›Šç‡åºåˆ—ï¼ˆè½¬æ¢ä¸ºå°æ•°å½¢å¼ç”¨äºè®¡ç®—ï¼‰
        daily_returns_pct = daily_pnl['æ—¥æ”¶ç›Šç‡'].values / 100
        total_returns_pct = daily_pnl['ç´¯è®¡æ”¶ç›Š'].iloc[-1] / initial_capital * 100 if len(daily_pnl) > 0 else 0
        
        # è·å–åŸºå‡†æ•°æ®ï¼ˆä½¿ç”¨ç¡¬ç¼–ç æ•°æ®ï¼‰
        benchmark_returns = BENCHMARK_RETURNS_HARDCODED.copy()
        
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        if len(benchmark_returns) != len(daily_returns_pct):
            min_len = min(len(benchmark_returns), len(daily_returns_pct))
            benchmark_returns = benchmark_returns[:min_len]
            daily_returns_pct_aligned = daily_returns_pct[:min_len]
            daily_pnl_aligned = daily_pnl.iloc[:min_len].copy()
        else:
            daily_returns_pct_aligned = daily_returns_pct
            daily_pnl_aligned = daily_pnl.copy()
        
        st.success(f"âœ… åŸºå‡†æ•°æ®ï¼Œå…± {len(benchmark_returns)} ä¸ªäº¤æ˜“æ—¥")
        
        # è®¡ç®—é£é™©æŒ‡æ ‡ï¼ˆä½¿ç”¨å¯¹é½åçš„daily_pnlï¼‰
        metrics = calculate_risk_metrics(daily_returns_pct_aligned, total_returns_pct, initial_capital, daily_pnl_aligned, benchmark_returns)
    
    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»äº¤æ˜“ç¬”æ•°", len(df))
    with col2:
        st.metric("äº¤æ˜“æ—¥æœŸèŒƒå›´", f"{daily_pnl['æ—¥æœŸ'].min().strftime('%Y-%m-%d')} è‡³ {daily_pnl['æ—¥æœŸ'].max().strftime('%Y-%m-%d')}")
    with col3:
        st.metric("æ€»ç›ˆäº", f"{df['å‡€ç›ˆäº'].sum():,.0f}")
    with col4:
        st.metric("åˆå§‹èµ„é‡‘", f"{initial_capital:,.0f}")
    
    st.divider()
    
    # é£é™©æŒ‡æ ‡å±•ç¤º
    st.header("ğŸ“ˆ é£é™©æŒ‡æ ‡")
    
    # å°†æŒ‡æ ‡åˆ†ä¸ºå¤šåˆ—æ˜¾ç¤º
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("æ”¶ç›ŠæŒ‡æ ‡")
        st.write(f"**Total Returns (ç­–ç•¥æ”¶ç›Š)**: {metrics.get('Total Returns', 0):.4f}%")
        st.write(f"**Total Annualized Returns (ç­–ç•¥å¹´åŒ–æ”¶ç›Š)**: {metrics.get('Total Annualized Returns', 0):.4f}%")
        st.write(f"**Alpha (é˜¿å°”æ³•)**: {metrics.get('Alpha', 0):.4f}%")
        st.write(f"**Beta (è´å¡”)**: {metrics.get('Beta', 0):.4f}")
        st.write(f"**AEI (æ—¥å‡è¶…é¢æ”¶ç›Š)**: {metrics.get('AEI', 0):.4f}%")
        st.write(f"**è¶…é¢æ”¶ç›Š**: {metrics.get('è¶…é¢æ”¶ç›Š', 0):.4f}%")
        st.write(f"**å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š**: {metrics.get('å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š', 0):.4f}%")
    
    with col2:
        st.subheader("é£é™©æŒ‡æ ‡")
        st.write(f"**Sharpe (å¤æ™®æ¯”ç‡)**: {metrics.get('Sharpe', 0):.4f}")
        st.write(f"**Sortino (ç´¢æè¯ºæ¯”ç‡)**: {metrics.get('Sortino', 0):.4f}")
        st.write(f"**Information Ratio (ä¿¡æ¯æ¯”ç‡)**: {metrics.get('Information Ratio', 0):.4f}")
        st.write(f"**Algorithm Volatility (ç­–ç•¥æ³¢åŠ¨ç‡)**: {metrics.get('Algorithm Volatility', 0):.4f}%")
        st.write(f"**Benchmark Volatility (åŸºå‡†æ³¢åŠ¨ç‡)**: {metrics.get('Benchmark Volatility', 0):.4f}%")
        st.write(f"**Max Drawdown (æœ€å¤§å›æ’¤)**: {metrics.get('Max Drawdown', 0):.4f}%")
        st.write(f"**Downside Risk (ä¸‹è¡Œæ³¢åŠ¨ç‡)**: {metrics.get('Downside Risk', 0):.4f}%")
    
    with col3:
        st.subheader("äº¤æ˜“ç»Ÿè®¡")
        st.write(f"**èƒœç‡**: {metrics.get('èƒœç‡', 0):.4f}%")
        st.write(f"**æ—¥èƒœç‡**: {metrics.get('æ—¥èƒœç‡', 0):.4f}%")
        st.write(f"**ç›ˆäºæ¯”**: {metrics.get('ç›ˆäºæ¯”', 0):.4f}")
        st.write(f"**è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤**: {metrics.get('è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤', 0):.4f}%")
        st.write(f"**è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡**: {metrics.get('è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡', 0):.4f}")
    
    st.divider()
    
    # äº¤æ˜“ä¿¡å·å›¾ï¼ˆä¸»è¦å›¾è¡¨ï¼‰
    st.header("ğŸ“Š äº¤æ˜“ä¿¡å·å›¾")
    st.info("ğŸ’¡ **äº¤æ˜“ä¿¡å·å›¾è¯´æ˜**ï¼šä¸Šå›¾æ˜¾ç¤ºä»·æ ¼èµ°åŠ¿ï¼Œç»¿è‰²â–²è¡¨ç¤ºä¹°å…¥ä¿¡å·ï¼ˆå¼€å¤šï¼‰ï¼Œçº¢è‰²â–¼è¡¨ç¤ºå–å‡ºä¿¡å·ï¼ˆå¹³å¤šï¼‰ã€‚ä¸‹å›¾æ˜¾ç¤ºæ¯ç¬”äº¤æ˜“çš„ç›ˆäºå’Œç´¯è®¡æ”¶ç›Šã€‚")
    
    fig_signals = plot_trading_signals(df)
    st.plotly_chart(fig_signals, use_container_width=True)
    
    st.divider()
    
    # é£é™©åˆ†æå›¾è¡¨
    st.header("ğŸ“ˆ é£é™©åˆ†æå›¾è¡¨")
    
    # å¯¹æ•°è½´é€‰é¡¹
    use_log_scale = st.checkbox("ä½¿ç”¨å¯¹æ•°è½´æ˜¾ç¤ºç´¯è®¡æ”¶ç›Š", value=False, 
                                help="åœ¨å¯¹æ•°è½´ä¸Šï¼Œç›¸åŒçš„ç™¾åˆ†æ¯”å˜åŒ–æ˜¾ç¤ºä¸ºç›¸åŒçš„è·ç¦»ï¼Œä¾¿äºæ¯”è¾ƒä¸åŒè§„æ¨¡çš„æŠ•èµ„è¡¨ç°")
    
    # ç»˜åˆ¶å›¾è¡¨
    fig = plot_risk_charts(df, daily_pnl, metrics, use_log_scale=use_log_scale)
    st.plotly_chart(fig, use_container_width=True)
    
    # æ•°æ®è¡¨æ ¼
    with st.expander("æŸ¥çœ‹è¯¦ç»†äº¤æ˜“æ•°æ®"):
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—ï¼ˆä½¿ç”¨å®é™…å­˜åœ¨çš„åˆ—åï¼‰
        display_cols = ['æ—¥æœŸ', 'å§”æ‰˜æ—¶é—´', 'æ ‡çš„', 'äº¤æ˜“ç±»å‹', 'æˆäº¤æ•°é‡']
        # æ·»åŠ ä»·æ ¼åˆ—ï¼ˆå¯èƒ½æ˜¯'æˆäº¤ä»·'æˆ–'æˆäº¤ä»·æ ¼'ï¼‰
        if 'æˆäº¤ä»·æ ¼' in df.columns:
            display_cols.append('æˆäº¤ä»·æ ¼')
        elif 'æˆäº¤ä»·' in df.columns:
            display_cols.append('æˆäº¤ä»·')
        # æ·»åŠ é‡‘é¢åˆ—ï¼ˆå¯èƒ½æ˜¯'æˆäº¤é¢'æˆ–'æˆäº¤é‡‘é¢'ï¼‰
        if 'æˆäº¤é‡‘é¢' in df.columns:
            display_cols.append('æˆäº¤é‡‘é¢')
        elif 'æˆäº¤é¢' in df.columns:
            display_cols.append('æˆäº¤é¢')
        display_cols.extend(['å¹³ä»“ç›ˆäº', 'æ‰‹ç»­è´¹', 'å‡€ç›ˆäº', 'ç´¯è®¡æ”¶ç›Š'])
        # åªæ˜¾ç¤ºå­˜åœ¨çš„åˆ—
        available_cols = [col for col in display_cols if col in df.columns]
        st.dataframe(df[available_cols], use_container_width=True)
    
    with st.expander("æŸ¥çœ‹æ—¥åº¦æ±‡æ€»æ•°æ®"):
        st.dataframe(daily_pnl, use_container_width=True)

if __name__ == "__main__":
    main()
