import pandas as pd 
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
import warnings
warnings.filterwarnings('ignore')

import akshare as ak  # è·å–AU0é»„é‡‘ä¸»åŠ›è¿ç»­åˆçº¦

# å¸¸é‡

Rf = 0.04                    # æ— é£é™©åˆ©ç‡
TRADING_DAYS_PER_YEAR = 250  # æ¯å¹´äº¤æ˜“æ—¥æ•°ï¼Œç”±èšå®½APIå…¬å¼å¾—åˆ°


#å…¬å…±é£é™©æŒ‡æ ‡å‡½æ•°

def get_total_returns(Pend, Pstart):
    """Total Returns ç­–ç•¥æ”¶ç›Š - Total Returns=(Pendâˆ’Pstart)/Pstartâˆ—100%"""
    if Pstart == 0:
        return 0.0
    return (Pend - Pstart) / Pstart * 100


def get_total_annualized_returns(P, n):
    """Total Annualized Returns ç­–ç•¥å¹´åŒ–æ”¶ç›Š - Rp=((1+P)çš„250/næ¬¡æ–¹âˆ’1)âˆ—100%"""
    if n <= 0:
        return 0.0
    return ((1 + P) ** (TRADING_DAYS_PER_YEAR / n) - 1) * 100


def get_beta(Dp, Dm):
    """Beta è´å¡” - Beta=Cov(Dp,Dm)/Var(Dm)"""
    if Dm is None:
        return 0.0
    min_len = min(len(Dp), len(Dm))
    Dp_clean = np.asarray(Dp[:min_len])
    Dm_clean = np.asarray(Dm[:min_len])
    mask = ~(np.isnan(Dp_clean) | np.isnan(Dm_clean) |
             np.isinf(Dp_clean) | np.isinf(Dm_clean))
    Dp_clean = Dp_clean[mask]
    Dm_clean = Dm_clean[mask]
    if len(Dp_clean) < 2:
        return 0.0
    cov = np.cov(Dp_clean, Dm_clean)[0, 1]
    var_dm = np.var(Dm_clean, ddof=0)
    return cov / var_dm if var_dm > 1e-10 else 0.0


def get_alpha(Rp, Rm, Î²p):
    """Alpha é˜¿å°”æ³• - Alpha=Rp-[Rf+Î²p(Rm-Rf)]ï¼Œè¿™é‡Œ Rp/Rm ä¼ å…¥ä¸ºå°æ•°å½¢å¼"""
    if Rm is None:
        return 0.0
    Î± = Rp - (Rf + Î²p * (Rm - Rf))
    return Î± * 100


def get_sharpe(Rp, Ïƒp):
    """Sharpe å¤æ™®æ¯”ç‡ - Sharpe=(Rp-Rf)/Ïƒpï¼ŒRpå’ŒÏƒpéƒ½æ˜¯å°æ•°å½¢å¼"""
    if Ïƒp is None or Ïƒp == 0 or Ïƒp < 1e-10:
        return 0.0
    return (Rp - Rf) / Ïƒp


def get_sortino(Rp, Ïƒpd):
    """Sortino ç´¢æè¯ºæ¯”ç‡ - Sortino=(Rp-Rf)/Ïƒpdï¼ŒRpå’ŒÏƒpdéƒ½æ˜¯å°æ•°å½¢å¼"""
    if Ïƒpd is None or Ïƒpd == 0 or Ïƒpd < 1e-10:
        return 0.0
    return (Rp - Rf) / Ïƒpd


def get_information_ratio(Rp, Rm, Dp, Dm):
    """Information Ratio ä¿¡æ¯æ¯”ç‡ - IR=(Rp-Rm)/Ïƒtï¼ŒRpå’ŒRmæ˜¯ç™¾åˆ†æ¯”å½¢å¼"""
    if Dm is None or Rm is None or len(Dp) < 2 or len(Dm) < 2:
        return 0.0
    
    n = min(len(Dp), len(Dm))
    excess = Dp[:n] - Dm[:n]  # ç­–ç•¥ä¸åŸºå‡†æ¯æ—¥æ”¶ç›Šå·®å€¼
    Ïƒt = np.std(excess, ddof=0) * np.sqrt(TRADING_DAYS_PER_YEAR) * 100  # å¹´åŒ–æ ‡å‡†å·®ï¼ˆ%ï¼‰
    
    return (Rp - Rm) / Ïƒt if Ïƒt > 1e-10 else 0.0


def get_algorithm_volatility(Dp):
    """Algorithm Volatility ç­–ç•¥æ³¢åŠ¨ç‡ - Ïƒp=æ ¹å·ä¸‹250/(nâˆ’1)*âˆ‘(rpâˆ’rpå‡å€¼)^2"""
    Dp_clean = np.asarray(Dp)
    Dp_clean = Dp_clean[~np.isnan(Dp_clean)]
    Dp_clean = Dp_clean[~np.isinf(Dp_clean)]
    if len(Dp_clean) < 2:
        return 0.0
    Ïƒp = np.std(Dp_clean, ddof=1) * np.sqrt(TRADING_DAYS_PER_YEAR) * 100
    return Ïƒp


def get_benchmark_volatility(Dm):
    """Benchmark Volatility åŸºå‡†æ³¢åŠ¨ç‡ - Ïƒm=æ ¹å·ä¸‹250/(nâˆ’1)*âˆ‘(rmâˆ’rmå‡å€¼)^2"""
    if Dm is None:
        return 0.0
    Dm_clean = np.asarray(Dm)
    Dm_clean = Dm_clean[~np.isnan(Dm_clean)]
    Dm_clean = Dm_clean[~np.isinf(Dm_clean)]
    if len(Dm_clean) < 2:
        return 0.0
    Ïƒm = np.std(Dm_clean, ddof=1) * np.sqrt(TRADING_DAYS_PER_YEAR) * 100
    return Ïƒm


def get_max_drawdown(Dp):
    """Max Drawdown æœ€å¤§å›æ’¤ - åŸºäºæƒç›Šæ›²çº¿"""
    r = np.asarray(Dp)
    r = r[~np.isnan(r)]
    r = r[~np.isinf(r)]
    if len(r) == 0:
        return 0.0
    cum = np.cumprod(1 + r) - 1
    running_max = np.maximum.accumulate(cum)
    dd = cum - running_max
    return np.min(dd) * 100


def get_downside_risk(Dp):
    """
    Downside Risk ä¸‹è¡Œæ³¢åŠ¨ç‡
    Ïƒpd=æ ¹å·ä¸‹(250/n)âˆ‘(rpâˆ’â–³rpiå‡å€¼)2f(t)
    rp=ç­–ç•¥æ¯æ—¥æ”¶ç›Šç‡, â–³rpiå‡å€¼=ç­–ç•¥è‡³ç¬¬iæ—¥å¹³å‡æ”¶ç›Šç‡=(1/i)âˆ‘(jä»1åˆ°i)rj
    f(t)=1 if rp<â–³rpi, f(t)=0 if rp>=â–³rpi
    """
    r = np.asarray(Dp)
    r = r[~np.isnan(r)]
    r = r[~np.isinf(r)]
    n = len(r)
    if n < 2:
        return 0.0
    downside_sum = 0.0
    for i in range(1, n + 1):  # iä»1åˆ°n
        rpi_mean = np.mean(r[0:i])  # è‡³ç¬¬iæ—¥å¹³å‡æ”¶ç›Šç‡
        rp_i = r[i - 1]  # ç¬¬iæ—¥æ”¶ç›Šç‡
        if rp_i < rpi_mean:
            downside_sum += (rp_i - rpi_mean) ** 2
    Ïƒpd = np.sqrt((TRADING_DAYS_PER_YEAR / n) * downside_sum) * 100
    return Ïƒpd

def get_win_rate(win_trades, loss_trades):
    """èƒœç‡ = ç›ˆåˆ©äº¤æ˜“æ¬¡æ•°/æ€»äº¤æ˜“æ¬¡æ•°"""
    total = win_trades + loss_trades
    return (win_trades / total * 100) if total > 0 else 0.0


def get_daily_win_rate(Dp, Dm):
    """æ—¥èƒœç‡ = å½“æ—¥ç­–ç•¥æ”¶ç›Šè·‘èµ¢å½“æ—¥åŸºå‡†æ”¶ç›Šçš„å¤©æ•°/æ€»äº¤æ˜“æ—¥æ•°"""
    if Dm is None:
        return 0.0
    min_len = min(len(Dp), len(Dm))
    sp = np.asarray(Dp[:min_len])
    bm = np.asarray(Dm[:min_len])
    mask = ~(np.isnan(sp) | np.isnan(bm) | np.isinf(sp) | np.isinf(bm))
    sp = sp[mask]
    bm = bm[mask]
    if len(sp) == 0:
        return 0.0
    return (sp > bm).sum() / len(sp) * 100


def get_profit_loss_ratio(total_profit, total_loss):
    """ç›ˆäºæ¯” = æ€»ç›ˆåˆ©é¢/æ€»äºæŸé¢"""
    return (total_profit / total_loss) if total_loss > 0 else 0.0


def get_aei(Dp, Dm):
    """AEI æ—¥å‡è¶…é¢æ”¶ç›Š"""
    if Dm is None:
        return 0.0
    min_len = min(len(Dp), len(Dm))
    sp = np.asarray(Dp[:min_len])
    bm = np.asarray(Dm[:min_len])
    mask = ~(np.isnan(sp) | np.isnan(bm) | np.isinf(sp) | np.isinf(bm))
    sp = sp[mask]
    bm = bm[mask]
    if len(sp) == 0:
        return 0.0
    sp_cum = np.cumprod(1 + sp) - 1
    bm_cum = np.cumprod(1 + bm) - 1
    ei = (1 + sp_cum) / (1 + bm_cum) - 1
    dei = np.diff(ei, prepend=0)
    return dei.mean() * 100


def get_excess_return_max_drawdown(Dp, Dm):
    """è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤"""
    if Dm is None:
        return 0.0
    min_len = min(len(Dp), len(Dm))
    sp = np.asarray(Dp[:min_len])
    bm = np.asarray(Dm[:min_len])
    mask = ~(np.isnan(sp) | np.isnan(bm) | np.isinf(sp) | np.isinf(bm))
    sp = sp[mask]
    bm = bm[mask]
    if len(sp) == 0:
        return 0.0
    sp_cum = np.cumprod(1 + sp) - 1
    bm_cum = np.cumprod(1 + bm) - 1
    ei = (1 + sp_cum) / (1 + bm_cum) - 1
    ei_running_max = np.maximum.accumulate(ei)
    dd = ei - ei_running_max
    return np.min(dd) * 100


def get_excess_return_sharpe(Dp, Dm):
    """è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡ EI Sharpe Ratio=(RpEI-Rf)/ÏƒpEI"""
    if Dm is None:
        return 0.0
    min_len = min(len(Dp), len(Dm))
    sp = np.asarray(Dp[:min_len])
    bm = np.asarray(Dm[:min_len])
    mask = ~(np.isnan(sp) | np.isnan(bm) | np.isinf(sp) | np.isinf(bm))
    sp = sp[mask]
    bm = bm[mask]
    if len(sp) < 2:
        return 0.0
    excess = sp - bm
    mean_excess = excess.mean()
    RpEI = mean_excess * TRADING_DAYS_PER_YEAR * 100  # å¹´åŒ–è¶…é¢æ”¶ç›Šç‡ï¼ˆ%ï¼‰
    ÏƒpEI = np.std(excess, ddof=0) * np.sqrt(TRADING_DAYS_PER_YEAR) * 100
    if ÏƒpEI == 0:
        return 0.0
    return (RpEI - Rf * 100) / ÏƒpEI

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç­–ç•¥é£é™©åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# åŠ è½½äº¤æ˜“æ•°æ®ï¼ˆä½¿ç”¨GBKç¼–ç ï¼‰
@st.cache_data
def load_trade_data(filename='jiaoyi.csv'):
    """åŠ è½½äº¤æ˜“æ•°æ®"""
    import os
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))#è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„ï¼Œos.path.dirname()è·å–å…¶çˆ¶ç›®å½•
    # æ‹¼æ¥å®Œæ•´è·¯å¾„
    csv_path = os.path.join(script_dir,filename)
    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(csv_path, encoding='gbk')
    return df

# æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
def preprocess_data(df):
    """ç®€åŒ–ç‰ˆæ•°æ®æ¸…æ´—"""
    df = df.copy()
    
    # 1. åˆå¹¶æ—¥æœŸæ—¶é—´ï¼ˆå‡è®¾åˆ—åå°±æ˜¯"æ—¥æœŸ"å’Œ"å§”æ‰˜æ—¶é—´"ï¼‰
    df['æ—¥æœŸæ—¶é—´'] = pd.to_datetime(df['æ—¥æœŸ'] + ' ' + df['å§”æ‰˜æ—¶é—´'], format='%Y/%m/%d %H:%M:%S', errors='coerce')
    df = df.sort_values('æ—¥æœŸæ—¶é—´').reset_index(drop=True)
    
    # 2. æ¸…ç†æ•°å­—åˆ—ï¼ˆç›´æ¥å¤„ç†ï¼Œä¸ç”¨ifåˆ¤æ–­ï¼‰
    # æˆäº¤æ•°é‡
    df['æˆäº¤æ•°é‡'] = pd.to_numeric(df['æˆäº¤æ•°é‡'].astype(str).str.replace('æ‰‹', ''), errors='coerce')
    
    # æˆäº¤ä»·
    df['æˆäº¤ä»·'] = pd.to_numeric(df['æˆäº¤ä»·'].astype(str).str.replace(',', ''), errors='coerce')
    
    # æˆäº¤é‡‘é¢
    df['æˆäº¤é¢'] = pd.to_numeric(df['æˆäº¤é¢'].astype(str).str.replace(',', ''), errors='coerce')
    
    # å¹³ä»“ç›ˆäº
    df['å¹³ä»“ç›ˆäº'] = pd.to_numeric(df['å¹³ä»“ç›ˆäº'].astype(str).str.replace(',', '').replace(['-', ''], '0'), errors='coerce').fillna(0)
    
    # æ‰‹ç»­è´¹
    df['æ‰‹ç»­è´¹'] = pd.to_numeric(df['æ‰‹ç»­è´¹'].astype(str).str.replace(',', '').replace(['-', ''], '0'), errors='coerce').fillna(0)
    
    # è®¡ç®—å‡€ç›ˆäº
    df['å‡€ç›ˆäº'] = df['å¹³ä»“ç›ˆäº'] - df['æ‰‹ç»­è´¹']
    
    return df

def calculate_risk_metrics(daily_returns, total_returns, initial_capital, daily_pnl, benchmark_returns=None, trade_df=None):
    """
    è®¡ç®—å„ç§é£é™©æŒ‡æ ‡
    å‚æ•°:
        daily_returns: ç­–ç•¥æ—¥æ”¶ç›Šç‡ï¼ˆå°æ•°å½¢å¼ï¼‰
        total_returns: ç­–ç•¥æ€»æ”¶ç›Šç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
        initial_capital: åˆå§‹èµ„é‡‘
        daily_pnl: DataFrameï¼ŒåŒ…å«æ—¥æœŸå’Œç´¯è®¡æ”¶ç›Š
        benchmark_returns: åŸºå‡†æ—¥æ”¶ç›Šç‡ï¼ˆå°æ•°å½¢å¼ï¼‰
        trade_df: DataFrameï¼ŒåŸå§‹äº¤æ˜“æ•°æ®ï¼Œç”¨äºè®¡ç®—èƒœç‡å’Œç›ˆäºæ¯”
    è¿”å›:
        dict: åŒ…å«æ‰€æœ‰é£é™©æŒ‡æ ‡çš„å­—å…¸
    """
    # è½¬ä¸º numpy å¹¶æ¸…ç†æ•°æ®
    if isinstance(daily_returns, pd.Series):
        daily_returns = daily_returns.values
    
    Dp = np.asarray(daily_returns)  # ç­–ç•¥æ¯æ—¥æ”¶ç›Š Dp
    Dp = Dp[~np.isnan(Dp)]
    Dp = Dp[~np.isinf(Dp)]
    if len(Dp) == 0:
        return {}
    
    # ç­–ç•¥æ”¶ç›Š P, Rp, Pstart, Pend
    Pstart = float(initial_capital)
    Pend = Pstart + float(daily_pnl['ç´¯è®¡æ”¶ç›Š'].iloc[-1]) if len(daily_pnl) > 0 else Pstart
    P = (Pend - Pstart) / Pstart if Pstart > 0 else 0.0  # ç­–ç•¥æ”¶ç›Šï¼ˆå°æ•°ï¼‰
    n = len(daily_pnl)  # ç­–ç•¥æ‰§è¡Œå¤©æ•°

    # åŸºå‡†æ”¶ç›Š Rm, Dm
    if benchmark_returns is not None:
        Dm = np.asarray(benchmark_returns)
        Dm = Dm[~np.isnan(Dm)]
        Dm = Dm[~np.isinf(Dm)]
        if len(Dm) == 0:
            Dm = None
    else:
        Dm = None

    if Dm is not None and len(Dm) > 0:
        bm_total = np.prod(1 + Dm) - 1
        n_bm = len(Dm)
        Rm = get_total_annualized_returns(bm_total, n_bm)  # åŸºå‡†å¹´åŒ–æ”¶ç›Šï¼ˆ%ï¼‰
    else:
        Rm = None

    # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆç™¾åˆ†æ¯”å½¢å¼ï¼‰
    Ïƒp_pct = get_algorithm_volatility(Dp)  # % å½¢å¼
    Ïƒm_pct = get_benchmark_volatility(Dm)  # % å½¢å¼
    Ïƒpd_pct = get_downside_risk(Dp)  # % å½¢å¼
    
    # è½¬æ¢ä¸ºå°æ•°å½¢å¼ï¼ˆç”¨äº Sharpe/Sortino è®¡ç®—ï¼‰
    Ïƒp = Ïƒp_pct / 100 if Ïƒp_pct > 0 else 0.0
    Ïƒpd = Ïƒpd_pct / 100 if Ïƒpd_pct > 0 else 0.0

    # è®¡ç®—é£é™©æŒ‡æ ‡
    Rp_pct = get_total_annualized_returns(P, n)  # ç­–ç•¥å¹´åŒ–æ”¶ç›Š Rpï¼ˆ%ï¼‰
    Rp = Rp_pct / 100  # è½¬æ¢ä¸ºå°æ•°å½¢å¼
    
    # åŸºå‡†å¹´åŒ–æ”¶ç›Šï¼ˆå°æ•°å½¢å¼ï¼‰
    if Rm is not None:
        Rm_decimal = Rm / 100  # Rm æ˜¯ç™¾åˆ†æ¯”ï¼Œè½¬æ¢ä¸ºå°æ•°
    else:
        Rm_decimal = None
    
    Î²p = get_beta(Dp, Dm)  # Beta
    alpha = get_alpha(Rp, Rm_decimal, Î²p) if Rm_decimal is not None else 0.0
    sharpe = get_sharpe(Rp, Ïƒp) if Ïƒp > 1e-10 else 0.0
    sortino = get_sortino(Rp, Ïƒpd) if Ïƒpd > 1e-10 else 0.0
    info_ratio = get_information_ratio(Rp_pct, Rm, Dp, Dm) if Rm is not None else 0.0

    # èƒœç‡å’Œç›ˆäºæ¯”ï¼ˆæŒ‰å®é™…äº¤æ˜“è®¡ç®—ï¼Œæ¯æ¬¡å–å‡ºè®°ä¸ºä¸€æ¬¡äº¤æ˜“ï¼‰
    if trade_df is not None and 'äº¤æ˜“ç±»å‹' in trade_df.columns and 'å¹³ä»“ç›ˆäº' in trade_df.columns:
        # ç­›é€‰å–å‡ºäº¤æ˜“ï¼ˆå¹³ä»“äº¤æ˜“ï¼‰
        close_mask = trade_df['äº¤æ˜“ç±»å‹'].astype(str).str.contains('å¹³', na=False)
        df_close = trade_df[close_mask].copy()
        
        if not df_close.empty:
            # è®¡ç®—èƒœç‡ï¼šç›ˆåˆ©äº¤æ˜“æ¬¡æ•° / æ€»äº¤æ˜“æ¬¡æ•°ï¼ˆåŒ…æ‹¬æ‰€æœ‰å¹³ä»“äº¤æ˜“ï¼Œå«ç›ˆäºä¸º0çš„ï¼‰
            win_mask = df_close['å¹³ä»“ç›ˆäº'] > 0
            loss_mask = df_close['å¹³ä»“ç›ˆäº'] < 0
            win_trades = win_mask.sum()
            loss_trades = loss_mask.sum()
            total_trades = len(df_close)  # æ‰€æœ‰å¹³ä»“äº¤æ˜“æ¬¡æ•°ï¼ŒåŒ…æ‹¬ç›ˆäºä¸º0çš„
            win_rate = (win_trades / total_trades * 100) if total_trades > 0 else 0.0
            
            # è®¡ç®—ç›ˆäºæ¯”ï¼šæ€»ç›ˆåˆ©é¢ / æ€»äºæŸé¢ï¼ˆç”¨å¹³ä»“ç›ˆäºï¼Œä¸å«æ‰‹ç»­è´¹ï¼‰
            total_profit = df_close[win_mask]['å¹³ä»“ç›ˆäº'].sum()  # æ€»ç›ˆåˆ©é¢ï¼ˆå¹³ä»“ç›ˆäºï¼Œæ­£æ•°ï¼‰
            total_loss = abs(df_close[loss_mask]['å¹³ä»“ç›ˆäº'].sum())  # æ€»äºæŸé¢ï¼ˆå¹³ä»“ç›ˆäºï¼Œç»å¯¹å€¼ï¼‰
            pl_ratio = (total_profit / total_loss) if total_loss > 0 else 0.0
        else:
            win_rate = 0.0
            pl_ratio = 0.0
    else:
        # å¦‚æœæ²¡æœ‰äº¤æ˜“æ•°æ®ï¼Œå›é€€åˆ°æŒ‰æ—¥æ”¶ç›Šè®¡ç®—
        winning_trades = (Dp > 0).sum()
        total_trades = len(Dp)
        win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0.0
        
        if winning_trades > 0 and (total_trades - winning_trades) > 0:
            avg_win = Dp[Dp > 0].mean()
            avg_loss = abs(Dp[Dp < 0].mean())
            pl_ratio = avg_win / avg_loss if avg_loss > 0 else 0.0
        else:
            pl_ratio = 0.0
    
    # æ—¥èƒœç‡å’Œå…¶ä»–è¶…é¢æŒ‡æ ‡
    daily_win_rate = get_daily_win_rate(Dp, Dm)
    aei = get_aei(Dp, Dm)
    excess_mdd = get_excess_return_max_drawdown(Dp, Dm)
    excess_sharpe = get_excess_return_sharpe(Dp, Dm)

    # è¶…é¢æ”¶ç›Šï¼ˆé™¤æ³•ç‰ˆï¼‰ä¸å¯¹æ•°è½´è¶…é¢æ”¶ç›Š
    if Dm is not None and len(Dm) > 0:
        min_len = min(len(Dp), len(Dm))
        sp = Dp[:min_len]
        bm = Dm[:min_len]
        mask = ~(np.isnan(sp) | np.isnan(bm) | np.isinf(sp) | np.isinf(bm))
        sp = sp[mask]
        bm = bm[mask]
        if len(sp) > 0:
            sp_total = np.prod(1 + sp) - 1
            bm_total = np.prod(1 + bm) - 1
            if abs(bm_total) > 1e-10:
                excess_div = (sp_total / bm_total - 1) * 100
                log_excess = (np.log1p(sp_total) - np.log1p(bm_total)) * 100
            else:
                excess_div = 0.0
                log_excess = 0.0
        else:
            excess_div = 0.0
            log_excess = 0.0
    else:
        excess_div = 0.0
        log_excess = 0.0

    metrics = {
        'Total Returns': get_total_returns(Pend, Pstart),
        'Total Annualized Returns': Rp_pct,
        'Alpha': alpha,
        'Beta': Î²p,
        'Sharpe': sharpe,
        'Sortino': sortino,
        'Information Ratio': info_ratio,
        'Algorithm Volatility': Ïƒp_pct,
        'Benchmark Volatility': Ïƒm_pct,
        'Max Drawdown': get_max_drawdown(Dp),
        'Downside Risk': Ïƒpd_pct,
        'èƒœç‡': win_rate,
        'æ—¥èƒœç‡': daily_win_rate,
        'ç›ˆäºæ¯”': pl_ratio,
        'AEI': aei,
        'è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤': excess_mdd,
        'è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡': excess_sharpe,
        'è¶…é¢æ”¶ç›Š': excess_div,
        'å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š': log_excess,
    }

    return metrics


@st.cache_data
def get_benchmark_daily_returns_aligned(trade_dates, symbol: str = "AU0"):
    """
    ä½¿ç”¨ akshare åŠ¨æ€è·å–åŸºå‡†ï¼ˆAU0 ä¸»åŠ›è¿ç»­åˆçº¦ï¼‰å¹¶å¯¹é½åˆ°äº¤æ˜“æ—¥æœŸï¼Œè¿”å›åŸºå‡†æ—¥æ”¶ç›Šç‡åºåˆ— Dmï¼ˆå°æ•°ï¼‰ã€‚
    """
    try:
        benchmark_df = ak.futures_zh_daily_sina(symbol=symbol)
    except Exception:
        return None

    if benchmark_df is None or benchmark_df.empty:
        return None

    # å¤„ç†æ—¥æœŸåˆ—
    if isinstance(benchmark_df.index, pd.DatetimeIndex):
        benchmark_df['æ—¥æœŸ'] = pd.to_datetime(benchmark_df.index)
    elif 'date' in benchmark_df.columns:
        benchmark_df['æ—¥æœŸ'] = pd.to_datetime(benchmark_df['date'], errors='coerce')
    else:
        first_col = benchmark_df.columns[0]
        benchmark_df['æ—¥æœŸ'] = pd.to_datetime(benchmark_df[first_col], errors='coerce')

    benchmark_df['æ—¥æœŸ'] = pd.to_datetime(benchmark_df['æ—¥æœŸ']).dt.normalize()

    # ç­›é€‰äº¤æ˜“æ—¥æœŸèŒƒå›´
    start_date = pd.to_datetime(trade_dates.min()).normalize()
    end_date = pd.to_datetime(trade_dates.max()).normalize()
    benchmark_df = benchmark_df[(benchmark_df['æ—¥æœŸ'] >= start_date) & (benchmark_df['æ—¥æœŸ'] <= end_date)].copy()
    benchmark_df = benchmark_df.sort_values('æ—¥æœŸ').reset_index(drop=True)

    if 'close' in benchmark_df.columns:
        prices = pd.to_numeric(benchmark_df['close'], errors='coerce').values
    else:
        return None

    valid_mask = ~np.isnan(prices)
    prices_clean = prices[valid_mask]
    dates_filtered = benchmark_df.loc[valid_mask, 'æ—¥æœŸ'].values

    if len(prices_clean) < 2:
        return None

    benchmark_returns_raw = np.diff(prices_clean) / prices_clean[:-1]
    benchmark_dates_raw = dates_filtered[1:]

    benchmark_df_aligned = pd.DataFrame({
        'æ—¥æœŸ': pd.to_datetime(benchmark_dates_raw).astype('datetime64[ns]').astype('datetime64[ns]').astype('datetime64[ns]').astype('datetime64[ns]'),
        'æ”¶ç›Šç‡': benchmark_returns_raw
    }).drop_duplicates(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)

    trade_df = pd.DataFrame({'æ—¥æœŸ': pd.to_datetime(trade_dates).dt.normalize()})

    merged = trade_df.merge(benchmark_df_aligned, on='æ—¥æœŸ', how='left')
    if merged['æ”¶ç›Šç‡'].isna().all():
        merged['æ”¶ç›Šç‡'] = 0.0
    else:
        if pd.isna(merged.loc[0, 'æ”¶ç›Šç‡']):
            merged.loc[0, 'æ”¶ç›Šç‡'] = 0.0
        merged['æ”¶ç›Šç‡'] = merged['æ”¶ç›Šç‡'].ffill().fillna(0.0)

    return merged['æ”¶ç›Šç‡'].values

# è·å– AU0 ä¸»åŠ›åˆçº¦æ”¶ç›˜ä»·æ•°æ®,æ ¹æ®æ”¶ç›˜ä»·ç»˜åˆ¶äº¤æ˜“ä¿¡å·å›¾ï¼Œä¿¡å·å›¾ç”»åœ¨æ”¶ç›˜ä»·æ›²çº¿ä¸Š
@st.cache_data
def get_au0_close_prices(start_date=None, end_date=None):
    """
    ä» akshare è·å– AU0 ä¸»åŠ›åˆçº¦çš„æ”¶ç›˜ä»·æ•°æ®
    
    å‚æ•°:
    start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD' æˆ– datetimeï¼Œæˆ– None
    end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD' æˆ– datetimeï¼Œæˆ– None
    
    è¿”å›:
    price_df: DataFrameï¼ŒåŒ…å« 'æ—¥æœŸ' å’Œ 'æ”¶ç›˜ä»·' åˆ—ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    try:
        # AU0 ä¸»åŠ›åˆçº¦æ•°æ®ä½œä¸ºåŸºå‡†
        df = ak.futures_zh_daily_sina(symbol="AU0")

        if df is None or df.empty:
            return None
        
        # å¤„ç†æ—¥æœŸåˆ—
        if isinstance(df.index, pd.DatetimeIndex):
            df['æ—¥æœŸ'] = pd.to_datetime(df.index)
        elif 'date' in df.columns:
            df['æ—¥æœŸ'] = pd.to_datetime(df['date'])
        elif 'æ—¥æœŸ' in df.columns:
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        else:
            # å°è¯•ç¬¬ä¸€åˆ—ä½œä¸ºæ—¥æœŸ
            first_col = df.columns[0]
            try:
                df['æ—¥æœŸ'] = pd.to_datetime(df[first_col])
            except:
                return None
        
        # è·å–æ”¶ç›˜ä»·åˆ—
        if 'close' in df.columns:
            df['æ”¶ç›˜ä»·'] = pd.to_numeric(df['close'], errors='coerce')
        elif 'æ”¶ç›˜' in df.columns:
            df['æ”¶ç›˜ä»·'] = pd.to_numeric(df['æ”¶ç›˜'], errors='coerce')
        elif 'æ”¶ç›˜ä»·' in df.columns:
            df['æ”¶ç›˜ä»·'] = pd.to_numeric(df['æ”¶ç›˜ä»·'], errors='coerce')
        else:
            # å°è¯•æ‰¾åˆ°åŒ…å«'close'æˆ–'æ”¶ç›˜'çš„åˆ—
            close_cols = [col for col in df.columns if 'close' in col.lower() or 'æ”¶ç›˜' in col]
            if close_cols:
                df['æ”¶ç›˜ä»·'] = pd.to_numeric(df[close_cols[0]], errors='coerce')
            else:
                return None
        
        # ç¡®ä¿æ—¥æœŸåˆ—ä¸º datetime ç±»å‹ï¼Œåªä¿ç•™æ—¥æœŸéƒ¨åˆ†
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ']).dt.normalize()
        
        # ç­›é€‰æ—¥æœŸèŒƒå›´
        if start_date is not None:
            start_date_dt = pd.to_datetime(start_date)
            df = df[df['æ—¥æœŸ'] >= start_date_dt]
        if end_date is not None:
            end_date_dt = pd.to_datetime(end_date)
            df = df[df['æ—¥æœŸ'] <= end_date_dt]
        
        # æ’åºå¹¶æ¸…ç†æ•°æ®
        df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        df = df.dropna(subset=['æ—¥æœŸ', 'æ”¶ç›˜ä»·'])
        
        # è¿”å›æ—¥æœŸå’Œæ”¶ç›˜ä»·
        result_df = df[['æ—¥æœŸ', 'æ”¶ç›˜ä»·']].copy()
        result_df = result_df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        
        return result_df if len(result_df) > 0 else None
        
    except Exception as e:
        return None

# ç»˜åˆ¶äº¤æ˜“ä¿¡å·å›¾
def plot_trading_signals(df):
    """
    ç»˜åˆ¶äº¤æ˜“ä¿¡å·å›¾ï¼Œæ˜¾ç¤ºä»·æ ¼èµ°åŠ¿å’Œä¹°å–ä¿¡å·ç‚¹
    ä¿¡å·å›¾ç»˜åˆ¶åœ¨ AU0 ä¸»åŠ›åˆçº¦çš„æ”¶ç›˜ä»·æ›²çº¿ä¸Šï¼Œè€ŒéæŠ˜çº¿å›¾
    """
    # åˆ›å»ºå­å›¾ï¼šä»…ä»·æ ¼èµ°åŠ¿ï¼ˆä¿¡å·å›¾å•ç‹¬ä¸€æ ï¼‰
    fig = make_subplots(
        rows=1, cols=1,
        
    )
    
    # æŒ‰æ—¥æœŸæ—¶é—´æ’åº
    df_sorted = df.sort_values('æ—¥æœŸæ—¶é—´').reset_index(drop=True)
    
    # è·å–äº¤æ˜“æ—¥æœŸèŒƒå›´
    start_date = df_sorted['æ—¥æœŸæ—¶é—´'].min()
    end_date = df_sorted['æ—¥æœŸæ—¶é—´'].max()
    
    # ä» akshare è·å– AU0 ä¸»åŠ›åˆçº¦æ”¶ç›˜ä»·æ•°æ®
    price_df = get_au0_close_prices(start_date=start_date, end_date=end_date)
    
    if price_df is not None and len(price_df) > 0:
        # ä½¿ç”¨æ”¶ç›˜ä»·æ•°æ®ç»˜åˆ¶ä»·æ ¼æ›²çº¿
        fig.add_trace(
            go.Scatter(
                x=price_df['æ—¥æœŸ'],
                y=price_df['æ”¶ç›˜ä»·'],
                mode='lines',
                name='AU0æ”¶ç›˜ä»·',
                line=dict(color='#1f77b4', width=2),
                hovertemplate='æ—¥æœŸ: %{x|%Y-%m-%d}<br>æ”¶ç›˜ä»·: %{y:.2f}<extra></extra>'
            ),
            row=1, col=1
        )
        
        # ä¸ºäº¤æ˜“ä¿¡å·æ‰¾åˆ°å¯¹åº”çš„æ”¶ç›˜ä»·
        # å°†äº¤æ˜“æ—¥æœŸæ—¶é—´è½¬æ¢ä¸ºæ—¥æœŸï¼ˆåªä¿ç•™æ—¥æœŸéƒ¨åˆ†ï¼‰
        df_sorted['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df_sorted['æ—¥æœŸæ—¶é—´']).dt.normalize()#normalize()å°†æ—¶é—´éƒ¨åˆ†è®¾ä¸º00:00:00
        
        # æå–ä¹°å…¥å’Œå–å‡ºä¿¡å·
        buy_signals = df_sorted[df_sorted['äº¤æ˜“ç±»å‹'].str.contains('å¼€å¤š', na=False)].copy()
        sell_signals = df_sorted[df_sorted['äº¤æ˜“ç±»å‹'].str.contains('å¹³å¤š', na=False)].copy()
        
        # æ ‡è®°ä¹°å…¥ä¿¡å·ï¼ˆå¼€å¤šï¼‰- ä½¿ç”¨æ”¶ç›˜ä»·
        if len(buy_signals) > 0:
            # åˆå¹¶æ”¶ç›˜ä»·æ•°æ®
            buy_signals = buy_signals.merge(
                price_df[['æ—¥æœŸ', 'æ”¶ç›˜ä»·']], 
                left_on='äº¤æ˜“æ—¥æœŸ', 
                right_on='æ—¥æœŸ', 
                how='left'
            )
            
            # å¦‚æœæŸå¤©æ²¡æœ‰æ”¶ç›˜ä»·ï¼Œä½¿ç”¨å‰å‘å¡«å……æˆ–åå‘å¡«å……
            buy_signals['æ”¶ç›˜ä»·'] = buy_signals['æ”¶ç›˜ä»·'].ffill().bfill()
            
            # è¿‡æ»¤æ‰ä»ç„¶æ²¡æœ‰æ”¶ç›˜ä»·çš„æ•°æ®
            buy_signals = buy_signals[buy_signals['æ”¶ç›˜ä»·'].notna()]#notna()ç”¨äºè¿‡æ»¤éç©ºå€¼
            
            if len(buy_signals) > 0:#åªæœ‰åœ¨æœ‰æœ‰æ•ˆæ•°æ®æ—¶æ‰æ·»åŠ æ ‡è®°
                fig.add_trace(#add_traceç”¨äºå‘å›¾è¡¨ä¸­æ·»åŠ æ•°æ®
                    go.Scatter(
                        x=buy_signals['æ—¥æœŸæ—¶é—´'],
                        y=buy_signals['æ”¶ç›˜ä»·'],
                        mode='markers',
                        name='ä¹°å…¥ä¿¡å·ï¼ˆå¼€å¤šï¼‰',
                        marker=dict(
                            symbol='triangle-up',
                            size=14,
                            color='green',
                            line=dict(width=2, color='darkgreen')
                        ),
                        hovertemplate=(
                            'ä¹°å…¥æ—¶é—´: %{x|%Y-%m-%d %H:%M:%S}<br>'
                            'æ”¶ç›˜ä»·: %{y:.2f}<br>'
                            'æˆäº¤ä»·: %{customdata[0]:.2f}<br>'
                            'æ•°é‡: %{customdata[1]}æ‰‹<extra></extra>'
                        ),
                        customdata=buy_signals[['æˆäº¤ä»·', 'æˆäº¤æ•°é‡']].values
                    ),
                    row=1, col=1
                )
        
        # æ ‡è®°å–å‡ºä¿¡å·ï¼ˆå¹³å¤šï¼‰- ä½¿ç”¨æ”¶ç›˜ä»·
        if len(sell_signals) > 0:
            # åˆå¹¶æ”¶ç›˜ä»·æ•°æ®
            sell_signals = sell_signals.merge(
                price_df[['æ—¥æœŸ', 'æ”¶ç›˜ä»·']], 
                left_on='äº¤æ˜“æ—¥æœŸ', 
                right_on='æ—¥æœŸ', 
                how='left'
            )
            
            # å¦‚æœæŸå¤©æ²¡æœ‰æ”¶ç›˜ä»·ï¼Œä½¿ç”¨å‰å‘å¡«å……æˆ–åå‘å¡«å……
            sell_signals['æ”¶ç›˜ä»·'] = sell_signals['æ”¶ç›˜ä»·'].ffill().bfill()
            
            # è¿‡æ»¤æ‰ä»ç„¶æ²¡æœ‰æ”¶ç›˜ä»·çš„æ•°æ®
            sell_signals = sell_signals[sell_signals['æ”¶ç›˜ä»·'].notna()]
            
            if len(sell_signals) > 0:
                fig.add_trace(
                    go.Scatter(
                        x=sell_signals['æ—¥æœŸæ—¶é—´'],
                        y=sell_signals['æ”¶ç›˜ä»·'],
                        mode='markers',
                        name='å–å‡ºä¿¡å·ï¼ˆå¹³å¤šï¼‰',
                        marker=dict(
                            symbol='triangle-down',
                            size=14,
                            color='red',
                            line=dict(width=2, color='darkred')
                        ),
                        hovertemplate=(
                            'å–å‡ºæ—¶é—´: %{x|%Y-%m-%d %H:%M:%S}<br>'
                            'æ”¶ç›˜ä»·: %{y:.2f}<br>'
                            'æˆäº¤ä»·: %{customdata[0]:.2f}<br>'
                            'ç›ˆäº: %{customdata[1]:.0f}<extra></extra>'
                        ),
                        customdata=sell_signals[['æˆäº¤ä»·', 'å¹³ä»“ç›ˆäº']].values
                    ),
                    row=1, col=1
                )
        
        # æ³¨æ„ï¼šä¸Šé¢å·²ç»åŸºäºæ”¶ç›˜ä»·ç”»è¿‡ä¸€æ¬¡ä¹°å…¥/å–å‡ºä¿¡å·ï¼Œè¿™é‡Œä¸å†é‡å¤ç”»åŸºäºæˆäº¤ä»·çš„ä¿¡å·ï¼Œé¿å…å›¾ä¸Šå‡ºç°é‡å¤ä¸‰è§’å½¢
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        height=800,
        title_text="äº¤æ˜“ä¿¡å·å›¾ï¼ˆåŸºäºæ”¶ç›˜ä»·æ›²çº¿ï¼‰",
        title_x=0.5,
        showlegend=True,
        hovermode='x unified',
        template='plotly_white'
    )
    
    # æ›´æ–°Yè½´æ ‡ç­¾
    if price_df is not None and len(price_df) > 0:
        fig.update_yaxes(title_text="AU0æ”¶ç›˜ä»·", row=1, col=1)
    else:
        fig.update_yaxes(title_text="æˆäº¤ä»·", row=1, col=1)
    
    # æ›´æ–°Xè½´æ—¥æœŸæ ¼å¼ï¼ˆä¸æ˜¾ç¤ºæ ‡ç­¾ï¼Œåªè®¾ç½®æ—¥æœŸæ ¼å¼ï¼‰
    fig.update_xaxes(tickformat="%Y-%m-%d", row=1, col=1)
    
    return fig

# ç»˜åˆ¶é£é™©æŒ‡æ ‡å›¾è¡¨
def plot_risk_charts(df, daily_pnl, metrics, use_log_scale=False):
    """
    ä½¿ç”¨Plotlyç»˜åˆ¶é£é™©æŒ‡æ ‡å›¾è¡¨
    
    å‚æ•°:
    - use_log_scale: æ˜¯å¦ä½¿ç”¨å¯¹æ•°è½´ï¼ˆå¯¹æ•°è½´è¯´æ˜ï¼šåœ¨å¯¹æ•°è½´ä¸Šï¼Œç›¸åŒçš„ç™¾åˆ†æ¯”å˜åŒ–æ˜¾ç¤ºä¸ºç›¸åŒçš„è·ç¦»ï¼Œ
                      ä¾¿äºæ¯”è¾ƒä¸åŒè§„æ¨¡çš„æŠ•èµ„è¡¨ç°ã€‚å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š = log(1+ç­–ç•¥æ”¶ç›Š) - log(1+åŸºå‡†æ”¶ç›Š)ï¼‰
    """
    
    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=4, cols=1,
        subplot_titles=('ç´¯è®¡æ”¶ç›Šæ›²çº¿', 'æ—¥ç›ˆäºåˆ†å¸ƒ', 'å›æ’¤æ›²çº¿', 'ç´¯è®¡æ”¶ç›Šç‡æ›²çº¿'),
        vertical_spacing=0.06,
        row_heights=[0.35, 0.2, 0.2, 0.25]
    )
    
    # 1. ç´¯è®¡æ”¶ç›Šæ›²çº¿ï¼ˆä¸»å›¾ï¼‰
    y_data = daily_pnl['ç´¯è®¡æ”¶ç›Š'].values
    yaxis_title = "ç´¯è®¡æ”¶ç›Š"
    
    if use_log_scale:
        # å¯¹äºå¯¹æ•°è½´ï¼Œéœ€è¦ç¡®ä¿æ‰€æœ‰å€¼ä¸ºæ­£æ•°
        y_min = y_data.min()
        if y_min <= 0:
            # å¦‚æœæœ‰è´Ÿå€¼æˆ–0å€¼ï¼Œéœ€è¦åç§»ä½¿æ‰€æœ‰å€¼ä¸ºæ­£
            # åç§»é‡ = abs(æœ€å°å€¼) + 1ï¼Œç¡®ä¿æœ€å°å€¼ä¸º1
            offset = abs(y_min) + 1
            y_data_log = y_data + offset
        else:
            # å¦‚æœæ‰€æœ‰å€¼éƒ½ä¸ºæ­£ï¼Œä½¿ç”¨åŸå§‹å€¼
            offset = 0
            y_data_log = y_data
        
        # ä½¿ç”¨å¯¹æ•°è½´æ˜¾ç¤º
        y_data = y_data_log
        yaxis_title = "ç´¯è®¡æ”¶ç›Š (å¯¹æ•°è½´)"
        
        # è®¡ç®—Yè½´èŒƒå›´ï¼Œç¡®ä¿èƒ½æ˜¾ç¤ºæ‰€æœ‰æ•°æ®
        y_max = y_data.max()
        y_min_log = y_data.min()
        # è®¾ç½®Yè½´èŒƒå›´ï¼Œç•™ä¸€äº›è¾¹è·
        # å¯¹äºå¯¹æ•°è½´ï¼Œæœ€å°å€¼è‡³å°‘ä¸º1ï¼ˆå› ä¸ºlog(1)=0ï¼‰ï¼Œä½†å¯ä»¥æ›´å°ä»¥æ˜¾ç¤ºæ›´å¤šç»†èŠ‚
        if y_min_log > 0:
            # ä½¿ç”¨æœ€å°å€¼çš„è¾ƒå°æ¯”ä¾‹ï¼Œä½†è‡³å°‘ä¸º1
            y_range_min = max(1, y_min_log * 0.3)  # è‡³å°‘ä»1å¼€å§‹ï¼Œæˆ–è€…æœ€å°å€¼çš„30%
        else:
            y_range_min = 1  # å¦‚æœæœ€å°å€¼å¼‚å¸¸ï¼Œè‡³å°‘ä»1å¼€å§‹
        y_range_max = y_max * 1.5  # æœ€å¤§å€¼å¢åŠ 50%çš„è¾¹è·ï¼Œç¡®ä¿èƒ½çœ‹åˆ°æ‰€æœ‰æ•°æ®
    else:
        offset = 0
        y_range_min = None
        y_range_max = None
    
    fig.add_trace(
        go.Scatter(
            x=daily_pnl['æ—¥æœŸ'],
            y=y_data,
            mode='lines+markers',
            name='ç´¯è®¡æ”¶ç›Š',
            line=dict(color='#1f77b4', width=2),
            marker=dict(size=3),
            hovertemplate='æ—¥æœŸ: %{x}<br>ç´¯è®¡æ”¶ç›Š: %{customdata:,.0f}<extra></extra>',
            customdata=daily_pnl['ç´¯è®¡æ”¶ç›Š'].values  # æ˜¾ç¤ºåŸå§‹å€¼
        ),
        row=1, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    if not use_log_scale:
        fig.add_hline(y=0, line_dash="dash", line_color="gray", row=1, col=1)
    
    # 2. æ—¥ç›ˆäºæ›²çº¿ï¼ˆæ”¹ä¸ºè¿ç»­æŠ˜çº¿è€Œä¸æ˜¯æŸ±çŠ¶ï¼Œé¿å…â€œç¦»æ•£ç‚¹â€çš„æ„Ÿè§‰ï¼‰
    colors = ['green' if x > 0 else 'red' for x in daily_pnl['æ—¥ç›ˆäº']]
    fig.add_trace(
        go.Scatter(
            x=daily_pnl['æ—¥æœŸ'],
            y=daily_pnl['æ—¥ç›ˆäº'],
            mode='lines+markers',
            name='æ—¥ç›ˆäº',
            line=dict(color='gray', width=1),
            marker=dict(color=colors, size=4),
            hovertemplate='æ—¥æœŸ: %{x}<br>æ—¥ç›ˆäº: %{y:,.0f}<extra></extra>'
        ),
        row=2, col=1
    )
    
    # 3. å›æ’¤æ›²çº¿
    cumulative = daily_pnl['ç´¯è®¡æ”¶ç›Š'].values
    running_max = np.maximum.accumulate(cumulative)
    drawdown = cumulative - running_max
    
    fig.add_trace(
        go.Scatter(
            x=daily_pnl['æ—¥æœŸ'],
            y=drawdown,
            mode='lines+markers',
            name='å›æ’¤',
            fill='tozeroy',
            fillcolor='rgba(255,0,0,0.3)',
            line=dict(color='red', width=1),
            marker=dict(size=3, color='red'),
            hovertemplate='æ—¥æœŸ: %{x}<br>å›æ’¤: %{y:,.0f}<extra></extra>'
        ),
        row=3, col=1
    )
    
    # 4. ç´¯è®¡æ”¶ç›Šç‡æ›²çº¿
    fig.add_trace(
        go.Scatter(
            x=daily_pnl['æ—¥æœŸ'],
            y=daily_pnl['ç´¯è®¡æ”¶ç›Šç‡'],
            mode='lines+markers',
            name='ç´¯è®¡æ”¶ç›Šç‡',
            line=dict(color='green', width=2),
            marker=dict(size=3, color='green'),
            hovertemplate='æ—¥æœŸ: %{x}<br>ç´¯è®¡æ”¶ç›Šç‡: %{y:.2f}%<extra></extra>'
        ),
        row=4, col=1
    )
    
    # æ·»åŠ é›¶çº¿
    fig.add_hline(y=0, line_dash="dash", line_color="gray", row=4, col=1)
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        height=1200,
        title_text="ç­–ç•¥é£é™©åˆ†æ",
        title_x=0.5,
        showlegend=True,
        hovermode='x unified',
        template='plotly_white'
    )
    
    # æ›´æ–°Yè½´æ ‡ç­¾
    if use_log_scale:
        # è®¾ç½®å¯¹æ•°è½´ç±»å‹å’ŒèŒƒå›´
        # Plotlyçš„å¯¹æ•°è½´rangeå‚æ•°ä½¿ç”¨å¯¹æ•°ç©ºé—´çš„å€¼ [log10(min), log10(max)]
        fig.update_yaxes(
            title_text=yaxis_title,
            type="log",
            range=[np.log10(y_range_min), np.log10(y_range_max)],
            row=1, col=1
        )
    else:
        fig.update_yaxes(title_text=yaxis_title, row=1, col=1)
    
    fig.update_yaxes(title_text="æ—¥ç›ˆäº", row=2, col=1)
    fig.update_yaxes(title_text="å›æ’¤", row=3, col=1)
    fig.update_yaxes(title_text="ç´¯è®¡æ”¶ç›Šç‡ (%)", row=4, col=1)
    
    # æ›´æ–°Xè½´æ—¥æœŸæ ¼å¼ï¼ˆä¸æ˜¾ç¤ºæ ‡ç­¾ï¼Œåªè®¾ç½®æ—¥æœŸæ ¼å¼ï¼‰
    fig.update_xaxes(tickformat="%Y-%m-%d", row=1, col=1)
    fig.update_xaxes(tickformat="%Y-%m-%d", row=2, col=1)
    fig.update_xaxes(tickformat="%Y-%m-%d", row=3, col=1)
    fig.update_xaxes(tickformat="%Y-%m-%d", row=4, col=1)
    
    return fig

# Streamlitä¸»ç•Œé¢
def main():
    st.title("ğŸ“Š é£é™©æŒ‡æ ‡ä¸äº¤æ˜“ä¿¡å·å›¾")
    
    # åŠ è½½æ•°æ®
    df = load_trade_data('jiaoyi.csv')
    
    if df is None:
        st.error("æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ jiaoyi.csv æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        return
    
    # æ•°æ®é¢„å¤„ç†
    with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®..."):
        df = preprocess_data(df)
        
        # è®¡ç®—ç´¯è®¡æ”¶ç›Š
        df['ç´¯è®¡æ”¶ç›Š'] = df['å‡€ç›ˆäº'].cumsum()
        
        # è®¡ç®—åˆå§‹èµ„é‡‘ï¼ˆä½¿ç”¨ç¬¬ä¸€ç¬”äº¤æ˜“çš„æˆäº¤é‡‘é¢ä½œä¸ºå‚è€ƒï¼‰
        initial_capital = abs(df['æˆäº¤é¢'].iloc[0]) if len(df) > 0 and df['æˆäº¤é¢'].iloc[0] != 0 else 1000000
        df['ç´¯è®¡æ”¶ç›Šç‡'] = (df['ç´¯è®¡æ”¶ç›Š'] / initial_capital) * 100
        
        # æŒ‰æ—¥æœŸèšåˆï¼ˆåŸºäºæˆäº¤è®°å½•å…ˆå¾—åˆ°â€œæœ‰äº¤æ˜“æ—¥â€çš„æ—¥ç›ˆäºï¼‰
        df['æ—¥æœŸ_ä»…'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y/%m/%d', errors='coerce')
        daily_pnl = df.groupby('æ—¥æœŸ_ä»…')['å‡€ç›ˆäº'].sum().reset_index()
        daily_pnl.columns = ['æ—¥æœŸ', 'æ—¥ç›ˆäº']
        daily_pnl = daily_pnl.sort_values('æ—¥æœŸ').reset_index(drop=True)

        # ä½¿ç”¨çœŸå®æœŸè´§äº¤æ˜“æ—¥å†è¡¥å…¨â€œæ— æˆäº¤æ—¥â€ï¼ˆé€æ—¥ç›¯å¸‚ï¼šæ— æˆäº¤æ—¥çš„æ—¥ç›ˆäº=0ï¼Œæƒç›Šæ¨ªç›˜ï¼‰
        price_calendar = get_au0_close_prices(
            start_date=daily_pnl['æ—¥æœŸ'].min(),
            end_date=daily_pnl['æ—¥æœŸ'].max()
        )
        if price_calendar is not None and len(price_calendar) > 0:
            all_days = price_calendar[['æ—¥æœŸ']].drop_duplicates().sort_values('æ—¥æœŸ')
            daily_pnl = all_days.merge(daily_pnl, on='æ—¥æœŸ', how='left')
        # æ— æˆäº¤æ—¥å¡«0
        daily_pnl['æ—¥ç›ˆäº'] = daily_pnl['æ—¥ç›ˆäº'].fillna(0.0)
        daily_pnl['ç´¯è®¡æ”¶ç›Š'] = daily_pnl['æ—¥ç›ˆäº'].cumsum()

        # æŒ‰ need.txt é€»è¾‘ï¼Œç”¨â€œå‰ä¸€æ—¥æƒç›Šâ€è®¡ç®—æ—¥æ”¶ç›Šç‡ï¼Œä½¿æƒç›Šæ›²çº¿å’Œå›¾è¡¨åœ¨æ‰€æœ‰äº¤æ˜“æ—¥è¿ç»­
        equity_prev = initial_capital + daily_pnl['ç´¯è®¡æ”¶ç›Š'].shift(1).fillna(0.0)
        equity_prev = equity_prev.replace(0, np.nan)
        daily_ret = daily_pnl['æ—¥ç›ˆäº'] / equity_prev
        if np.isnan(daily_ret.iloc[0]):
            daily_ret.iloc[0] = daily_pnl['æ—¥ç›ˆäº'].iloc[0] / initial_capital
        daily_ret = daily_ret.replace([np.inf, -np.inf], np.nan).fillna(0.0)

        daily_pnl['æ—¥æ”¶ç›Šç‡'] = daily_ret * 100
        daily_pnl['ç´¯è®¡æ”¶ç›Šç‡'] = (daily_pnl['ç´¯è®¡æ”¶ç›Š'] / initial_capital) * 100
        
        # è®¡ç®—æ—¥æ”¶ç›Šç‡åºåˆ—ï¼ˆå°æ•°å½¢å¼ï¼‰
        daily_returns_pct = daily_ret.values
        total_returns_pct = daily_pnl['ç´¯è®¡æ”¶ç›Š'].iloc[-1] / initial_capital * 100 if len(daily_pnl) > 0 else 0
        
        # ä½¿ç”¨ akshare åŠ¨æ€è·å–åŸºå‡†æ•°æ®å¹¶å¯¹é½åˆ°äº¤æ˜“æ—¥æœŸ
        benchmark_returns = get_benchmark_daily_returns_aligned(daily_pnl['æ—¥æœŸ'])
        
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        if benchmark_returns is not None and len(benchmark_returns) != len(daily_returns_pct):
            min_len = min(len(benchmark_returns), len(daily_returns_pct))
            benchmark_returns = benchmark_returns[:min_len]
            daily_returns_pct_aligned = daily_returns_pct[:min_len]
            daily_pnl_aligned = daily_pnl.iloc[:min_len].copy()
        else:
            daily_returns_pct_aligned = daily_returns_pct
            daily_pnl_aligned = daily_pnl.copy()
        
        st.success(f"âœ… äº¤æ˜“è¯¦æƒ…æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(daily_pnl_aligned)} ä¸ªäº¤æ˜“æ—¥")
        
        # è®¡ç®—é£é™©æŒ‡æ ‡ï¼ˆä½¿ç”¨å¯¹é½åçš„ daily_pnl å’ŒåŸºå‡†ï¼Œä¼ å…¥åŸå§‹äº¤æ˜“æ•°æ®ç”¨äºè®¡ç®—èƒœç‡å’Œç›ˆäºæ¯”ï¼‰
        metrics = calculate_risk_metrics(daily_returns_pct_aligned, total_returns_pct, initial_capital, daily_pnl_aligned, benchmark_returns, trade_df=df)
    
    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»äº¤æ˜“ç¬”æ•°", len(df))
    with col2:
        st.metric("äº¤æ˜“æ—¥æœŸèŒƒå›´", f"{daily_pnl['æ—¥æœŸ'].min().strftime('%Y-%m-%d')} è‡³ {daily_pnl['æ—¥æœŸ'].max().strftime('%Y-%m-%d')}")
    with col3:
        st.metric("æ€»ç›ˆäº", f"{df['å‡€ç›ˆäº'].sum():,.0f}")
    with col4:
        st.metric("åˆå§‹èµ„é‡‘", f"{initial_capital:,.0f}")
    
    st.divider()
    
    # é£é™©æŒ‡æ ‡å±•ç¤º
    st.header("ğŸ“ˆ é£é™©æŒ‡æ ‡")
    
    # å°†æŒ‡æ ‡åˆ†ä¸ºå¤šåˆ—æ˜¾ç¤º
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("æ”¶ç›ŠæŒ‡æ ‡")
        st.write(f"**Total Returns (ç­–ç•¥æ”¶ç›Š)**: {metrics.get('Total Returns', 0):.4f}%")
        st.write(f"**Total Annualized Returns (ç­–ç•¥å¹´åŒ–æ”¶ç›Š)**: {metrics.get('Total Annualized Returns', 0):.4f}%")
        st.write(f"**Alpha (é˜¿å°”æ³•)**: {metrics.get('Alpha', 0):.4f}%")
        st.write(f"**Beta (è´å¡”)**: {metrics.get('Beta', 0):.4f}")
        st.write(f"**AEI (æ—¥å‡è¶…é¢æ”¶ç›Š)**: {metrics.get('AEI', 0):.4f}%")
        st.write(f"**è¶…é¢æ”¶ç›Š**: {metrics.get('è¶…é¢æ”¶ç›Š', 0):.4f}%")
        st.write(f"**å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š**: {metrics.get('å¯¹æ•°è½´ä¸Šçš„è¶…é¢æ”¶ç›Š', 0):.4f}%")
    
    with col2:
        st.subheader("é£é™©æŒ‡æ ‡")
        st.write(f"**Sharpe (å¤æ™®æ¯”ç‡)**: {metrics.get('Sharpe', 0):.4f}")
        st.write(f"**Sortino (ç´¢æè¯ºæ¯”ç‡)**: {metrics.get('Sortino', 0):.4f}")
        st.write(f"**Information Ratio (ä¿¡æ¯æ¯”ç‡)**: {metrics.get('Information Ratio', 0):.4f}")
        st.write(f"**Algorithm Volatility (ç­–ç•¥æ³¢åŠ¨ç‡)**: {metrics.get('Algorithm Volatility', 0):.4f}%")
        st.write(f"**Benchmark Volatility (åŸºå‡†æ³¢åŠ¨ç‡)**: {metrics.get('Benchmark Volatility', 0):.4f}%")
        st.write(f"**Max Drawdown (æœ€å¤§å›æ’¤)**: {metrics.get('Max Drawdown', 0):.4f}%")
        st.write(f"**Downside Risk (ä¸‹è¡Œæ³¢åŠ¨ç‡)**: {metrics.get('Downside Risk', 0):.4f}%")
    
    with col3:
        st.subheader("äº¤æ˜“ç»Ÿè®¡")
        st.write(f"**èƒœç‡**: {metrics.get('èƒœç‡', 0):.4f}%")
        st.write(f"**æ—¥èƒœç‡**: {metrics.get('æ—¥èƒœç‡', 0):.4f}%")
        st.write(f"**ç›ˆäºæ¯”**: {metrics.get('ç›ˆäºæ¯”', 0):.4f}")
        st.write(f"**è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤**: {metrics.get('è¶…é¢æ”¶ç›Šæœ€å¤§å›æ’¤', 0):.4f}%")
        st.write(f"**è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡**: {metrics.get('è¶…é¢æ”¶ç›Šå¤æ™®æ¯”ç‡', 0):.4f}")
    
    st.divider()
    
    st.header("é£é™©æŒ‡æ ‡æ€»ç»“")
    
    # åŠ¨æ€ç”Ÿæˆæ€»ç»“ï¼Œä½¿ç”¨å®é™…è®¡ç®—å‡ºçš„æŒ‡æ ‡
    total_returns = metrics.get('Total Returns', 0)
    annualized_returns = metrics.get('Total Annualized Returns', 0)
    alpha = metrics.get('Alpha', 0)
    excess_return = metrics.get('è¶…é¢æ”¶ç›Š', 0)
    beta = metrics.get('Beta', 0)
    sharpe = metrics.get('Sharpe', 0)
    sortino = metrics.get('Sortino', 0)
    max_drawdown = metrics.get('Max Drawdown', 0)
    algo_vol = metrics.get('Algorithm Volatility', 0)
    bench_vol = metrics.get('Benchmark Volatility', 0)
    win_rate = metrics.get('èƒœç‡', 0)
    pl_ratio = metrics.get('ç›ˆäºæ¯”', 0)
    daily_win_rate = metrics.get('æ—¥èƒœç‡', 0)
    
    # ç”Ÿæˆè¯„ä»·æ–‡æœ¬
    alpha_desc = "ç›¸å¯¹åŸºå‡†è·‘èµ¢" if alpha > 0 else "ç›¸å¯¹åŸºå‡†è·‘è¾“"
    excess_desc = "ç›¸å¯¹åŸºå‡†è·‘èµ¢" if excess_return > 0 else "ç›¸å¯¹åŸºå‡†è·‘è¾“"
    beta_desc = "ç­–ç•¥æ³¢åŠ¨æ€§æ¥è¿‘å¸‚åœº" if abs(beta - 1.0) < 0.2 else ("ç­–ç•¥æ³¢åŠ¨æ€§é«˜äºå¸‚åœº" if beta > 1.0 else "ç­–ç•¥æ³¢åŠ¨æ€§ä½äºå¸‚åœº")
    sortino_desc = "ä¸‹è¡Œé£é™©æ§åˆ¶ä¼˜äºæ€»é£é™©æ§åˆ¶" if sortino > sharpe else "ä¸‹è¡Œé£é™©æ§åˆ¶ä¸€èˆ¬"
    volatility_desc = "ç­–ç•¥æ³¢åŠ¨ç•¥é«˜äºå¸‚åœº" if algo_vol > bench_vol else "ç­–ç•¥æ³¢åŠ¨ä½äºå¸‚åœº"
    win_rate_desc = "æ‹©æ—¶å‡†ç¡®ç‡" + ("è¾ƒé«˜" if win_rate > 50 else "åä½" if win_rate < 30 else "ä¸­ç­‰")
    pl_ratio_desc = "ç›ˆäºç»“æ„ä¼˜ç§€ï¼ŒäºæŸå°é¢ï¼Œç›ˆåˆ©å¤§å¹…" if pl_ratio > 2.0 else "ç›ˆäºç»“æ„ä¸€èˆ¬"
    daily_win_rate_desc = "æ—¥åº¦è¡¨ç°ä¼˜äºåŸºå‡†" if daily_win_rate > 50 else "æ—¥åº¦è¡¨ç°ç•¥ä½äºåŸºå‡†"
    
    st.markdown(f"""
        - **æ€»æ”¶ç›Š**: {total_returns:.2f}% | **å¹´åŒ–æ”¶ç›Š**: {annualized_returns:.2f}% 
        - **Alpha**: {alpha:.2f}% ({alpha_desc}) | **è¶…é¢æ”¶ç›Š**: {excess_return:.2f}% ({excess_desc})
        - **Beta**: {beta:.2f} ({beta_desc})

        **é£é™©è°ƒæ•´åæ”¶ç›Š**
        - **å¤æ™®æ¯”ç‡**: {sharpe:.2f} | **ç´¢æè¯ºæ¯”ç‡**: {sortino:.2f} ({sortino_desc})
        - **æœ€å¤§å›æ’¤**: {max_drawdown:.2f}% (é£é™©æ§åˆ¶èƒ½åŠ›{'è¾ƒå¼º' if abs(max_drawdown) < 10 else 'ä¸€èˆ¬'})
        - **æ³¢åŠ¨ç‡**: {algo_vol:.2f}% vs åŸºå‡† {bench_vol:.2f}% ({volatility_desc})

        **äº¤æ˜“ç‰¹å¾**
        - **èƒœç‡**: {win_rate:.2f}% ({win_rate_desc})
        - **ç›ˆäºæ¯”**: {pl_ratio:.2f} ({pl_ratio_desc})
        - **æ—¥èƒœç‡**: {daily_win_rate:.2f}% ({daily_win_rate_desc})
            """)
    
    # äº¤æ˜“ä¿¡å·å›¾ï¼ˆä¸»è¦å›¾è¡¨ï¼‰
    st.divider()
    st.header("ğŸ“ˆ äº¤æ˜“ä¿¡å·å›¾")
    fig = plot_trading_signals(df)
    st.plotly_chart(fig, use_container_width=True)
    with st.expander("æŸ¥çœ‹è¯¦ç»†äº¤æ˜“æ•°æ®"):
        display_cols = ['æ—¥æœŸ', 'å§”æ‰˜æ—¶é—´', 'æ ‡çš„', 'äº¤æ˜“ç±»å‹', 'æˆäº¤æ•°é‡']
        display_cols.append('æˆäº¤ä»·')
        display_cols.append('æˆäº¤é¢')
        display_cols.extend(['å¹³ä»“ç›ˆäº', 'æ‰‹ç»­è´¹', 'å‡€ç›ˆäº', 'ç´¯è®¡æ”¶ç›Š'])
        available_cols = [col for col in display_cols if col in df.columns]
        st.dataframe(df[available_cols], use_container_width=True)
    with st.expander("æŸ¥çœ‹æ—¥åº¦æ±‡æ€»æ•°æ®"):
        st.dataframe(daily_pnl, use_container_width=True)

if __name__ == "__main__":
    main()
